{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"제주어 번역모델 seq2seq.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"YyqzqejiL3Be","colab_type":"code","outputId":"6cdcc314-2fa5-4ac7-bc80-ee6ff7a97541","executionInfo":{"status":"ok","timestamp":1582016628376,"user_tz":-540,"elapsed":1167,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["try:\n","  # %tensorflow_version only exists in Colab.\n","  %tensorflow_version 2.x\n","except Exception:\n","  pass\n","import tensorflow as tf"],"execution_count":141,"outputs":[{"output_type":"stream","text":["TensorFlow is already loaded. Please restart the runtime to change versions.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"-1NpPu-13bgd","colab_type":"text"},"source":["https://neurowhai.tistory.com/292\n","\n","# seq2seq with attention mechanism"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"7f17c8fb-31e5-4df0-8da6-6fd7d67c039f","executionInfo":{"status":"ok","timestamp":1582017325399,"user_tz":-540,"elapsed":2267,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}},"id":"b60dnspGim-g","colab":{"base_uri":"https://localhost:8080/","height":100}},"source":["import tensorflow as tf\n","tf.__version__"],"execution_count":1,"outputs":[{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}},{"output_type":"execute_result","data":{"text/plain":["'1.15.0'"]},"metadata":{"tags":[]},"execution_count":1}]},{"cell_type":"code","metadata":{"id":"Pa4IReo6Cc7a","colab_type":"code","outputId":"60464f34-7aea-4367-881e-5a220fac5309","executionInfo":{"status":"ok","timestamp":1582017329236,"user_tz":-540,"elapsed":2538,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}},"colab":{"base_uri":"https://localhost:8080/","height":503}},"source":["from tensorflow.python.client import device_lib\n","import tensorflow as tf\n","device_lib.list_local_devices()\n"],"execution_count":2,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[name: \"/device:CPU:0\"\n"," device_type: \"CPU\"\n"," memory_limit: 268435456\n"," locality {\n"," }\n"," incarnation: 2265206407884039409, name: \"/device:XLA_CPU:0\"\n"," device_type: \"XLA_CPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 13914434809359195673\n"," physical_device_desc: \"device: XLA_CPU device\", name: \"/device:XLA_GPU:0\"\n"," device_type: \"XLA_GPU\"\n"," memory_limit: 17179869184\n"," locality {\n"," }\n"," incarnation: 569608369167759954\n"," physical_device_desc: \"device: XLA_GPU device\", name: \"/device:GPU:0\"\n"," device_type: \"GPU\"\n"," memory_limit: 15956161332\n"," locality {\n","   bus_id: 1\n","   links {\n","   }\n"," }\n"," incarnation: 268424367306140864\n"," physical_device_desc: \"device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0\"]"]},"metadata":{"tags":[]},"execution_count":2}]},{"cell_type":"code","metadata":{"id":"-xGdGylMFawA","colab_type":"code","outputId":"780cfe6c-13a0-4fdd-b3bb-f48b11e10ab4","executionInfo":{"status":"ok","timestamp":1582017332488,"user_tz":-540,"elapsed":1123,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["import tensorflow as tf\n","tf.test.gpu_device_name()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'/device:GPU:0'"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"yom9Uyon4NVf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":127},"outputId":"80b4e482-da21-427a-9e9d-b234e49c656e","executionInfo":{"status":"ok","timestamp":1582017352332,"user_tz":-540,"elapsed":18232,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":4,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SZFA3lB73uGm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"6a49c594-abb2-4f72-e42e-638ee440a10b","executionInfo":{"status":"ok","timestamp":1582017355178,"user_tz":-540,"elapsed":2716,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["from keras import layers, models\n","from __future__ import print_function\n","from keras.callbacks import EarlyStopping, ModelCheckpoint\n","from keras.models import Model\n","from keras.layers import Input, LSTM, Dense, Bidirectional, Dropout, Embedding\n","import numpy as np\n","from keras import datasets\n","from keras import backend as K\n","from keras.utils import plot_model\n","import matplotlib\n","from matplotlib import ticker\n","import matplotlib.pyplot as plt\n","\n","batch_size = 64  # Batch size for training.\n","epochs = 100  # Number of epochs to train for.\n","latent_dim = 256  # Latent dimensionality of the encoding space.\n","num_samples = 10000  # Number of samples to train on.\n","# Path to the data txt file on disk.\n","data_path = '/content/drive/My Drive/jeju_real.txt'\n","\n","\n","# Vectorize the data.\n","input_texts = []\n","target_texts = []\n","input_characters = set()\n","target_characters = set()\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n') # 각 문장. 일단 줄바꿈으로 한줄씩 불러옴\n","    \n","for line in lines[: min(num_samples, len(lines) - 1)]:\n","    input_text, target_text = line.split('\\t')\n","    # We use \"tab\" as the \"start sequence\" character\n","    # for the targets, and \"\\n\" as \"end sequence\" character.\n","    target_text = '\\t' + target_text + '\\n'\n","    input_texts.append(input_text)\n","    target_texts.append(target_text)\n","    for char in input_text:\n","        if char not in input_characters:\n","            input_characters.add(char)\n","    for char in target_text:\n","        if char not in target_characters:\n","            target_characters.add(char)\n","\n","            #  제주어사투리와 번역표준어를 불러와서 줄로 나눈뒤\n","            #  탭으로 구분된 문장 나눔\n"],"execution_count":5,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"1uGmhNAx3uJO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"ea64e7a1-0eac-4968-d7d8-4c839cf9d8f3","executionInfo":{"status":"ok","timestamp":1582017359485,"user_tz":-540,"elapsed":1099,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# input_characters = set() ; target_characters = set() \n","# 집합으로 되어있는 각각의 음절의 모음을 list 로 변형시킨후 자주나오는 빈도로 변형시킴\n","\n","input_characters = sorted(list(input_characters))\n","target_characters = sorted(list(target_characters))\n","num_encoder_tokens = len(input_characters)\n","num_decoder_tokens = len(target_characters)\n","max_encoder_seq_length = max([len(txt) for txt in input_texts])\n","max_decoder_seq_length = max([len(txt) for txt in target_texts])\n","\n","print('제주어 문장 총 갯수:', len(input_texts))\n","print('제주어 음절 수:', num_encoder_tokens)\n","print('표준어 음절 수 :', num_decoder_tokens)\n","print('제주어 문장의 음절 최대길이:', max_encoder_seq_length)\n","print('표준어 번역문장 음절 최대길이:', max_decoder_seq_length)\n"],"execution_count":6,"outputs":[{"output_type":"stream","text":["제주어 문장 총 갯수: 1174\n","제주어 음절 수: 777\n","표준어 음절 수 : 717\n","제주어 문장의 음절 최대길이: 165\n","표준어 번역문장 음절 최대길이: 183\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"eD-ogAFR35jt","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"outputId":"a187b9e5-503b-497a-e3ee-e8397b8a2e8d","executionInfo":{"status":"ok","timestamp":1582017361431,"user_tz":-540,"elapsed":703,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 문자 -> 숫자 변환용 사전\n","input_token_index = dict(\n","    [(char, i) for i, char in enumerate(input_characters)])\n","target_token_index = dict(\n","    [(char, i) for i, char in enumerate(target_characters)])\n","\n","# 음절 - 인덱스\n","print(input_token_index)\n","print(target_token_index)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["{' ': 0, '!': 1, \"'\": 2, ',': 3, '.': 4, '0': 5, '1': 6, '3': 7, '4': 8, '5': 9, '?': 10, '`': 11, '가': 12, '각': 13, '간': 14, '갈': 15, '감': 16, '갑': 17, '갓': 18, '갔': 19, '강': 20, '같': 21, '개': 22, '갭': 23, '갯': 24, '갱': 25, '거': 26, '걱': 27, '건': 28, '걷': 29, '걸': 30, '검': 31, '것': 32, '겅': 33, '게': 34, '겐': 35, '겡': 36, '겨': 37, '겼': 38, '경': 39, '고': 40, '곡': 41, '곤': 42, '곧': 43, '골': 44, '곰': 45, '곱': 46, '곳': 47, '공': 48, '과': 49, '관': 50, '광': 51, '괭': 52, '괴': 53, '괸': 54, '교': 55, '구': 56, '국': 57, '군': 58, '굴': 59, '굶': 60, '굼': 61, '굽': 62, '굿': 63, '궂': 64, '궐': 65, '궤': 66, '귀': 67, '그': 68, '근': 69, '글': 70, '금': 71, '급': 72, '기': 73, '긴': 74, '길': 75, '김': 76, '깅': 77, '까': 78, '깍': 79, '깐': 80, '깝': 81, '깨': 82, '깬': 83, '깽': 84, '꺼': 85, '껀': 86, '껍': 87, '껏': 88, '께': 89, '껭': 90, '껴': 91, '꼬': 92, '꼭': 93, '꼴': 94, '꼼': 95, '꼽': 96, '꽃': 97, '꽈': 98, '꽉': 99, '꽝': 100, '꾸': 101, '꿀': 102, '꿈': 103, '꿩': 104, '꿰': 105, '뀐': 106, '끄': 107, '끅': 108, '끈': 109, '끌': 110, '끔': 111, '끼': 112, '낀': 113, '나': 114, '낚': 115, '난': 116, '날': 117, '남': 118, '납': 119, '낫': 120, '났': 121, '낭': 122, '낮': 123, '내': 124, '낸': 125, '냄': 126, '냉': 127, '냐': 128, '냑': 129, '냥': 130, '너': 131, '널': 132, '넘': 133, '네': 134, '넬': 135, '넹': 136, '녀': 137, '녁': 138, '년': 139, '녕': 140, '녜': 141, '노': 142, '놀': 143, '놈': 144, '놉': 145, '놋': 146, '농': 147, '놓': 148, '놩': 149, '누': 150, '눈': 151, '뉠': 152, '느': 153, '늑': 154, '는': 155, '늘': 156, '늙': 157, '능': 158, '늬': 159, '니': 160, '닌': 161, '님': 162, '다': 163, '닥': 164, '단': 165, '달': 166, '닮': 167, '담': 168, '답': 169, '닷': 170, '당': 171, '대': 172, '댄': 173, '댕': 174, '더': 175, '덕': 176, '던': 177, '덜': 178, '덩': 179, '덮': 180, '데': 181, '덴': 182, '뎅': 183, '뎌': 184, '도': 185, '독': 186, '돈': 187, '돋': 188, '돌': 189, '돔': 190, '돗': 191, '동': 192, '됐': 193, '되': 194, '된': 195, '두': 196, '둑': 197, '둘': 198, '둠': 199, '둡': 200, '둣': 201, '둥': 202, '뒤': 203, '드': 204, '득': 205, '든': 206, '듣': 207, '들': 208, '듬': 209, '듭': 210, '듯': 211, '등': 212, '듸': 213, '디': 214, '딘': 215, '딱': 216, '땅': 217, '때': 218, '땐': 219, '땡': 220, '떠': 221, '떡': 222, '떨': 223, '떵': 224, '떻': 225, '또': 226, '똑': 227, '똔': 228, '똘': 229, '똠': 230, '똣': 231, '똥': 232, '뚜': 233, '뚝': 234, '뚱': 235, '뜨': 236, '뜩': 237, '뜰': 238, '뜻': 239, '띠': 240, '라': 241, '락': 242, '란': 243, '람': 244, '랍': 245, '랏': 246, '랐': 247, '랑': 248, '래': 249, '랜': 250, '랭': 251, '량': 252, '러': 253, '럭': 254, '런': 255, '럽': 256, '렀': 257, '렁': 258, '레': 259, '렌': 260, '렝': 261, '려': 262, '련': 263, '렴': 264, '렵': 265, '령': 266, '로': 267, '록': 268, '롬': 269, '롱': 270, '루': 271, '룩': 272, '룬': 273, '룸': 274, '룹': 275, '룽': 276, '르': 277, '른': 278, '를': 279, '름': 280, '릅': 281, '릇': 282, '리': 283, '린': 284, '릴': 285, '림': 286, '립': 287, '링': 288, '마': 289, '막': 290, '만': 291, '많': 292, '말': 293, '맑': 294, '맙': 295, '맛': 296, '망': 297, '맞': 298, '맥': 299, '맨': 300, '맹': 301, '머': 302, '먹': 303, '멀': 304, '멋': 305, '멍': 306, '메': 307, '멕': 308, '멘': 309, '멜': 310, '멩': 311, '면': 312, '명': 313, '모': 314, '목': 315, '몬': 316, '몰': 317, '몸': 318, '못': 319, '몽': 320, '무': 321, '묵': 322, '묶': 323, '문': 324, '물': 325, '뭇': 326, '뭉': 327, '뭐': 328, '미': 329, '민': 330, '믿': 331, '밀': 332, '밑': 333, '바': 334, '박': 335, '반': 336, '발': 337, '밤': 338, '밥': 339, '밧': 340, '방': 341, '밭': 342, '배': 343, '백': 344, '밸': 345, '뱁': 346, '뱃': 347, '뱅': 348, '버': 349, '벅': 350, '벌': 351, '범': 352, '벗': 353, '벙': 354, '베': 355, '벡': 356, '벤': 357, '벨': 358, '벳': 359, '벵': 360, '별': 361, '병': 362, '보': 363, '복': 364, '본': 365, '볼': 366, '봅': 367, '봉': 368, '봐': 369, '봔': 370, '봥': 371, '뵈': 372, '부': 373, '북': 374, '분': 375, '불': 376, '붑': 377, '붓': 378, '붙': 379, '븐': 380, '비': 381, '빈': 382, '빌': 383, '빗': 384, '빙': 385, '빠': 386, '빡': 387, '뺄': 388, '뻘': 389, '뽀': 390, '뽈': 391, '뿌': 392, '뿐': 393, '쁜': 394, '삐': 395, '삔': 396, '사': 397, '삭': 398, '산': 399, '살': 400, '삶': 401, '삼': 402, '삽': 403, '상': 404, '새': 405, '샛': 406, '생': 407, '서': 408, '석': 409, '섞': 410, '선': 411, '설': 412, '섭': 413, '섯': 414, '성': 415, '세': 416, '센': 417, '셔': 418, '셩': 419, '소': 420, '속': 421, '손': 422, '솔': 423, '솖': 424, '솜': 425, '솟': 426, '송': 427, '쇠': 428, '수': 429, '숙': 430, '순': 431, '숟': 432, '술': 433, '숨': 434, '숭': 435, '쉐': 436, '쉬': 437, '쉰': 438, '스': 439, '슨': 440, '슬': 441, '슴': 442, '승': 443, '시': 444, '식': 445, '신': 446, '실': 447, '심': 448, '십': 449, '싯': 450, '싱': 451, '싶': 452, '싸': 453, '싼': 454, '쌍': 455, '써': 456, '썰': 457, '썸': 458, '썹': 459, '썼': 460, '쎄': 461, '쏘': 462, '쏟': 463, '쏠': 464, '쑤': 465, '쓰': 466, '쓸': 467, '씀': 468, '씌': 469, '씨': 470, '씩': 471, '씬': 472, '씸': 473, '씻': 474, '아': 475, '악': 476, '안': 477, '앉': 478, '않': 479, '알': 480, '암': 481, '앗': 482, '았': 483, '앙': 484, '앚': 485, '앞': 486, '애': 487, '액': 488, '앤': 489, '앨': 490, '야': 491, '약': 492, '얄': 493, '양': 494, '어': 495, '억': 496, '언': 497, '얼': 498, '엄': 499, '엇': 500, '었': 501, '엉': 502, '에': 503, '엔': 504, '엥': 505, '여': 506, '역': 507, '연': 508, '열': 509, '염': 510, '영': 511, '옆': 512, '예': 513, '옌': 514, '옛': 515, '오': 516, '옥': 517, '온': 518, '올': 519, '옴': 520, '옵': 521, '옷': 522, '와': 523, '왁': 524, '완': 525, '왐': 526, '왓': 527, '왔': 528, '왕': 529, '외': 530, '왼': 531, '요': 532, '욕': 533, '용': 534, '우': 535, '욱': 536, '운': 537, '울': 538, '움': 539, '웁': 540, '웃': 541, '워': 542, '원': 543, '월': 544, '웠': 545, '웡': 546, '위': 547, '윌': 548, '유': 549, '융': 550, '으': 551, '은': 552, '을': 553, '음': 554, '읍': 555, '읏': 556, '의': 557, '이': 558, '인': 559, '일': 560, '잃': 561, '임': 562, '입': 563, '잇': 564, '있': 565, '자': 566, '작': 567, '잘': 568, '잠': 569, '잡': 570, '장': 571, '재': 572, '잰': 573, '쟁': 574, '저': 575, '전': 576, '절': 577, '젊': 578, '점': 579, '접': 580, '정': 581, '제': 582, '젠': 583, '젯': 584, '젱': 585, '져': 586, '졈': 587, '졌': 588, '졍': 589, '조': 590, '족': 591, '존': 592, '졸': 593, '좀': 594, '좁': 595, '종': 596, '좋': 597, '죄': 598, '죙': 599, '주': 600, '죽': 601, '준': 602, '줄': 603, '줌': 604, '줍': 605, '중': 606, '줘': 607, '줨': 608, '줬': 609, '쥐': 610, '즙': 611, '지': 612, '직': 613, '진': 614, '질': 615, '짐': 616, '집': 617, '짓': 618, '짚': 619, '짝': 620, '째': 621, '짹': 622, '쩌': 623, '쪼': 624, '쪽': 625, '쫄': 626, '쭈': 627, '찌': 628, '찍': 629, '차': 630, '착': 631, '찾': 632, '채': 633, '처': 634, '척': 635, '천': 636, '첩': 637, '청': 638, '체': 639, '쳉': 640, '쳐': 641, '쳤': 642, '초': 643, '촌': 644, '촐': 645, '촘': 646, '촙': 647, '촛': 648, '총': 649, '추': 650, '춘': 651, '춤': 652, '췀': 653, '취': 654, '치': 655, '친': 656, '칠': 657, '칩': 658, '칭': 659, '카': 660, '칼': 661, '캐': 662, '캠': 663, '커': 664, '컨': 665, '케': 666, '켜': 667, '켬': 668, '코': 669, '콥': 670, '콩': 671, '콰': 672, '쿠': 673, '쿨': 674, '퀴': 675, '크': 676, '큰': 677, '큼': 678, '큽': 679, '키': 680, '타': 681, '탁': 682, '탄': 683, '탈': 684, '탕': 685, '태': 686, '택': 687, '탱': 688, '터': 689, '턱': 690, '털': 691, '텃': 692, '텅': 693, '테': 694, '텔': 695, '텡': 696, '토': 697, '톨': 698, '통': 699, '톼': 700, '투': 701, '퉁': 702, '트': 703, '특': 704, '튼': 705, '틀': 706, '틉': 707, '티': 708, '틴': 709, '파': 710, '판': 711, '팔': 712, '팝': 713, '팡': 714, '패': 715, '팽': 716, '펀': 717, '페': 718, '펜': 719, '펭': 720, '편': 721, '폐': 722, '포': 723, '폭': 724, '폿': 725, '퐁': 726, '푸': 727, '푼': 728, '풀': 729, '품': 730, '풍': 731, '프': 732, '픈': 733, '픔': 734, '피': 735, '핀': 736, '핏': 737, '하': 738, '한': 739, '할': 740, '함': 741, '합': 742, '항': 743, '해': 744, '핵': 745, '핸': 746, '햄': 747, '햇': 748, '했': 749, '행': 750, '허': 751, '헌': 752, '헐': 753, '험': 754, '헙': 755, '헴': 756, '혈': 757, '호': 758, '혼': 759, '홀': 760, '홈': 761, '홉': 762, '홍': 763, '화': 764, '확': 765, '황': 766, '훌': 767, '훼': 768, '휘': 769, '흐': 770, '흘': 771, '흙': 772, '흥': 773, '흰': 774, '히': 775, '힌': 776}\n","{'\\t': 0, '\\n': 1, ' ': 2, '!': 3, \"'\": 4, ',': 5, '.': 6, '0': 7, '1': 8, '3': 9, '4': 10, '5': 11, '?': 12, '`': 13, 'g': 14, 'k': 15, '가': 16, '각': 17, '간': 18, '갈': 19, '감': 20, '갑': 21, '값': 22, '갓': 23, '갔': 24, '강': 25, '같': 26, '개': 27, '걀': 28, '거': 29, '걱': 30, '건': 31, '걷': 32, '걸': 33, '검': 34, '겁': 35, '것': 36, '겋': 37, '게': 38, '겠': 39, '겨': 40, '결': 41, '겼': 42, '경': 43, '계': 44, '고': 45, '곡': 46, '곧': 47, '곰': 48, '곱': 49, '곳': 50, '공': 51, '과': 52, '관': 53, '광': 54, '괭': 55, '교': 56, '구': 57, '국': 58, '군': 59, '굴': 60, '굵': 61, '굶': 62, '굼': 63, '굿': 64, '궁': 65, '궈': 66, '귀': 67, '귓': 68, '그': 69, '근': 70, '글': 71, '금': 72, '급': 73, '긋': 74, '기': 75, '긴': 76, '긷': 77, '길': 78, '김': 79, '깊': 80, '까': 81, '깐': 82, '깝': 83, '깨': 84, '깬': 85, '꺼': 86, '껏': 87, '께': 88, '꼬': 89, '꼭': 90, '꼼': 91, '꼽': 92, '꽁': 93, '꽂': 94, '꽃': 95, '꽉': 96, '꾀': 97, '꾸': 98, '꾼': 99, '꿀': 100, '꿈': 101, '뀐': 102, '끄': 103, '끈': 104, '끌': 105, '끓': 106, '끔': 107, '끗': 108, '끝': 109, '끼': 110, '낀': 111, '나': 112, '난': 113, '날': 114, '남': 115, '납': 116, '낫': 117, '났': 118, '낮': 119, '낳': 120, '내': 121, '낼': 122, '냐': 123, '냥': 124, '너': 125, '넓': 126, '넘': 127, '넣': 128, '네': 129, '녀': 130, '녁': 131, '년': 132, '녕': 133, '노': 134, '놀': 135, '놈': 136, '놓': 137, '누': 138, '눈': 139, '느': 140, '늑': 141, '는': 142, '늘': 143, '늙': 144, '늦': 145, '늬': 146, '니': 147, '닌': 148, '닐': 149, '님': 150, '닙': 151, '다': 152, '닥': 153, '단': 154, '달': 155, '닭': 156, '닮': 157, '담': 158, '답': 159, '닷': 160, '당': 161, '대': 162, '더': 163, '덕': 164, '던': 165, '덜': 166, '덟': 167, '덩': 168, '덮': 169, '데': 170, '덴': 171, '도': 172, '독': 173, '돈': 174, '돌': 175, '돔': 176, '동': 177, '돼': 178, '됐': 179, '되': 180, '된': 181, '될': 182, '됩': 183, '두': 184, '둑': 185, '둘': 186, '둠': 187, '둡': 188, '둣': 189, '둥': 190, '뒤': 191, '뒹': 192, '드': 193, '득': 194, '든': 195, '듣': 196, '들': 197, '듭': 198, '듯': 199, '등': 200, '디': 201, '따': 202, '딸': 203, '땀': 204, '땅': 205, '땋': 206, '때': 207, '땠': 208, '떠': 209, '떡': 210, '떤': 211, '떨': 212, '떵': 213, '떻': 214, '뗀': 215, '또': 216, '똑': 217, '똥': 218, '뚝': 219, '뚫': 220, '뚱': 221, '뛰': 222, '뛴': 223, '뜨': 224, '뜬': 225, '뜻': 226, '띠': 227, '라': 228, '락': 229, '란': 230, '람': 231, '랍': 232, '랐': 233, '랑': 234, '랗': 235, '래': 236, '랜': 237, '랬': 238, '랭': 239, '랴': 240, '러': 241, '런': 242, '럼': 243, '럽': 244, '렀': 245, '렁': 246, '렇': 247, '레': 248, '려': 249, '련': 250, '렴': 251, '렵': 252, '렸': 253, '례': 254, '로': 255, '록': 256, '롭': 257, '롱': 258, '루': 259, '룩': 260, '르': 261, '른': 262, '를': 263, '름': 264, '릅': 265, '릇': 266, '릎': 267, '리': 268, '린': 269, '릴': 270, '림': 271, '립': 272, '마': 273, '막': 274, '만': 275, '많': 276, '말': 277, '맑': 278, '맙': 279, '맛': 280, '망': 281, '맞': 282, '매': 283, '맨': 284, '맴': 285, '맷': 286, '맹': 287, '맺': 288, '머': 289, '먹': 290, '먼': 291, '멋': 292, '멍': 293, '멓': 294, '메': 295, '멘': 296, '멜': 297, '며': 298, '멱': 299, '면': 300, '명': 301, '모': 302, '목': 303, '몫': 304, '몸': 305, '못': 306, '무': 307, '묶': 308, '문': 309, '물': 310, '뭇': 311, '뭐': 312, '뭔': 313, '뭘': 314, '믄': 315, '미': 316, '믿': 317, '밀': 318, '밑': 319, '바': 320, '박': 321, '반': 322, '받': 323, '발': 324, '밝': 325, '밟': 326, '밤': 327, '밥': 328, '방': 329, '밭': 330, '배': 331, '백': 332, '뱀': 333, '뱃': 334, '버': 335, '벅': 336, '번': 337, '벌': 338, '범': 339, '법': 340, '벗': 341, '벙': 342, '베': 343, '벵': 344, '벼': 345, '변': 346, '별': 347, '병': 348, '볕': 349, '보': 350, '복': 351, '본': 352, '볼': 353, '봅': 354, '봐': 355, '봤': 356, '부': 357, '북': 358, '분': 359, '불': 360, '붓': 361, '붙': 362, '비': 363, '빈': 364, '빌': 365, '빗': 366, '빙': 367, '빛': 368, '빠': 369, '빨': 370, '뺨': 371, '뻘': 372, '뼈': 373, '뿌': 374, '뿐': 375, '쁘': 376, '쁜': 377, '삐': 378, '사': 379, '삭': 380, '삯': 381, '산': 382, '살': 383, '삶': 384, '삼': 385, '삽': 386, '삿': 387, '상': 388, '새': 389, '색': 390, '샛': 391, '생': 392, '서': 393, '섞': 394, '선': 395, '설': 396, '섭': 397, '섯': 398, '성': 399, '세': 400, '센': 401, '셔': 402, '셨': 403, '소': 404, '속': 405, '손': 406, '솔': 407, '송': 408, '쇠': 409, '수': 410, '순': 411, '숟': 412, '술': 413, '숨': 414, '숫': 415, '숭': 416, '쉐': 417, '스': 418, '슨': 419, '슬': 420, '슴': 421, '습': 422, '승': 423, '시': 424, '식': 425, '신': 426, '실': 427, '싫': 428, '심': 429, '십': 430, '싶': 431, '싸': 432, '쌀': 433, '쌌': 434, '쌍': 435, '쌓': 436, '써': 437, '썩': 438, '썰': 439, '썹': 440, '쎄': 441, '쏟': 442, '쑥': 443, '쓰': 444, '쓸': 445, '씀': 446, '씨': 447, '씩': 448, '씬': 449, '아': 450, '안': 451, '앉': 452, '않': 453, '알': 454, '암': 455, '앗': 456, '았': 457, '앞': 458, '애': 459, '액': 460, '야': 461, '약': 462, '얀': 463, '얇': 464, '양': 465, '얘': 466, '어': 467, '억': 468, '언': 469, '얼': 470, '엄': 471, '없': 472, '엇': 473, '었': 474, '엉': 475, '엊': 476, '엌': 477, '에': 478, '엔': 479, '여': 480, '엮': 481, '연': 482, '열': 483, '염': 484, '였': 485, '영': 486, '옆': 487, '예': 488, '옛': 489, '오': 490, '옥': 491, '온': 492, '올': 493, '옮': 494, '옵': 495, '옷': 496, '와': 497, '왁': 498, '왔': 499, '왕': 500, '왜': 501, '외': 502, '왼': 503, '요': 504, '욕': 505, '용': 506, '우': 507, '운': 508, '울': 509, '움': 510, '웁': 511, '웃': 512, '워': 513, '원': 514, '월': 515, '웠': 516, '위': 517, '윗': 518, '유': 519, '으': 520, '은': 521, '을': 522, '음': 523, '읍': 524, '의': 525, '이': 526, '익': 527, '인': 528, '일': 529, '잃': 530, '입': 531, '있': 532, '자': 533, '작': 534, '잔': 535, '잖': 536, '잘': 537, '잠': 538, '잡': 539, '장': 540, '재': 541, '쟁': 542, '저': 543, '적': 544, '전': 545, '절': 546, '젊': 547, '점': 548, '접': 549, '젓': 550, '정': 551, '제': 552, '져': 553, '졌': 554, '조': 555, '족': 556, '졸': 557, '좀': 558, '종': 559, '좋': 560, '죄': 561, '죠': 562, '주': 563, '죽': 564, '준': 565, '줄': 566, '줌': 567, '줍': 568, '중': 569, '줘': 570, '줬': 571, '쥐': 572, '즉': 573, '즐': 574, '즙': 575, '지': 576, '진': 577, '질': 578, '짐': 579, '집': 580, '짓': 581, '짚': 582, '짜': 583, '짝': 584, '째': 585, '짹': 586, '쨍': 587, '쩌': 588, '쩔': 589, '쪽': 590, '찌': 591, '찍': 592, '찐': 593, '찡': 594, '차': 595, '착': 596, '찬': 597, '찮': 598, '참': 599, '찹': 600, '찾': 601, '채': 602, '챙': 603, '처': 604, '척': 605, '천': 606, '철': 607, '첩': 608, '청': 609, '체': 610, '쳐': 611, '쳤': 612, '초': 613, '촉': 614, '촌': 615, '총': 616, '추': 617, '춤': 618, '치': 619, '친': 620, '칠': 621, '칡': 622, '침': 623, '카': 624, '칼': 625, '캄': 626, '커': 627, '켜': 628, '켠': 629, '코': 630, '콤': 631, '콩': 632, '쾌': 633, '크': 634, '큰': 635, '큼': 636, '키': 637, '타': 638, '탄': 639, '탕': 640, '태': 641, '터': 642, '턱': 643, '털': 644, '텃': 645, '텅': 646, '테': 647, '텐': 648, '텔': 649, '통': 650, '투': 651, '퉁': 652, '퉈': 653, '특': 654, '틀': 655, '틈': 656, '티': 657, '파': 658, '팍': 659, '팔': 660, '팡': 661, '팥': 662, '패': 663, '팽': 664, '편': 665, '평': 666, '포': 667, '폭': 668, '푸': 669, '푼': 670, '풀': 671, '품': 672, '풍': 673, '프': 674, '픈': 675, '픔': 676, '피': 677, '핀': 678, '하': 679, '학': 680, '한': 681, '할': 682, '함': 683, '합': 684, '항': 685, '해': 686, '햇': 687, '했': 688, '향': 689, '허': 690, '헌': 691, '험': 692, '헤': 693, '현': 694, '혈': 695, '형': 696, '호': 697, '혼': 698, '홀': 699, '화': 700, '확': 701, '황': 702, '횃': 703, '후': 704, '훔': 705, '흉': 706, '흐': 707, '흔': 708, '흘': 709, '흙': 710, '흥': 711, '흩': 712, '희': 713, '흰': 714, '히': 715, '힘': 716}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"tQzU8pCB3uM0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":73},"outputId":"d9c8884d-5bcb-41db-be3f-2415fd5c25eb","executionInfo":{"status":"ok","timestamp":1582017364026,"user_tz":-540,"elapsed":1122,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 숫자 -> 문자 변환용 사전\n","reverse_input_char_index = dict(\n","    (i, char) for char, i in input_token_index.items())\n","reverse_target_char_index = dict(\n","    (i, char) for char, i in target_token_index.items())\n","\n","\n","# 순서바꿈 : 인덱스 - 음절\n","print(reverse_input_char_index)\n","print(reverse_target_char_index)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["{0: ' ', 1: '!', 2: \"'\", 3: ',', 4: '.', 5: '0', 6: '1', 7: '3', 8: '4', 9: '5', 10: '?', 11: '`', 12: '가', 13: '각', 14: '간', 15: '갈', 16: '감', 17: '갑', 18: '갓', 19: '갔', 20: '강', 21: '같', 22: '개', 23: '갭', 24: '갯', 25: '갱', 26: '거', 27: '걱', 28: '건', 29: '걷', 30: '걸', 31: '검', 32: '것', 33: '겅', 34: '게', 35: '겐', 36: '겡', 37: '겨', 38: '겼', 39: '경', 40: '고', 41: '곡', 42: '곤', 43: '곧', 44: '골', 45: '곰', 46: '곱', 47: '곳', 48: '공', 49: '과', 50: '관', 51: '광', 52: '괭', 53: '괴', 54: '괸', 55: '교', 56: '구', 57: '국', 58: '군', 59: '굴', 60: '굶', 61: '굼', 62: '굽', 63: '굿', 64: '궂', 65: '궐', 66: '궤', 67: '귀', 68: '그', 69: '근', 70: '글', 71: '금', 72: '급', 73: '기', 74: '긴', 75: '길', 76: '김', 77: '깅', 78: '까', 79: '깍', 80: '깐', 81: '깝', 82: '깨', 83: '깬', 84: '깽', 85: '꺼', 86: '껀', 87: '껍', 88: '껏', 89: '께', 90: '껭', 91: '껴', 92: '꼬', 93: '꼭', 94: '꼴', 95: '꼼', 96: '꼽', 97: '꽃', 98: '꽈', 99: '꽉', 100: '꽝', 101: '꾸', 102: '꿀', 103: '꿈', 104: '꿩', 105: '꿰', 106: '뀐', 107: '끄', 108: '끅', 109: '끈', 110: '끌', 111: '끔', 112: '끼', 113: '낀', 114: '나', 115: '낚', 116: '난', 117: '날', 118: '남', 119: '납', 120: '낫', 121: '났', 122: '낭', 123: '낮', 124: '내', 125: '낸', 126: '냄', 127: '냉', 128: '냐', 129: '냑', 130: '냥', 131: '너', 132: '널', 133: '넘', 134: '네', 135: '넬', 136: '넹', 137: '녀', 138: '녁', 139: '년', 140: '녕', 141: '녜', 142: '노', 143: '놀', 144: '놈', 145: '놉', 146: '놋', 147: '농', 148: '놓', 149: '놩', 150: '누', 151: '눈', 152: '뉠', 153: '느', 154: '늑', 155: '는', 156: '늘', 157: '늙', 158: '능', 159: '늬', 160: '니', 161: '닌', 162: '님', 163: '다', 164: '닥', 165: '단', 166: '달', 167: '닮', 168: '담', 169: '답', 170: '닷', 171: '당', 172: '대', 173: '댄', 174: '댕', 175: '더', 176: '덕', 177: '던', 178: '덜', 179: '덩', 180: '덮', 181: '데', 182: '덴', 183: '뎅', 184: '뎌', 185: '도', 186: '독', 187: '돈', 188: '돋', 189: '돌', 190: '돔', 191: '돗', 192: '동', 193: '됐', 194: '되', 195: '된', 196: '두', 197: '둑', 198: '둘', 199: '둠', 200: '둡', 201: '둣', 202: '둥', 203: '뒤', 204: '드', 205: '득', 206: '든', 207: '듣', 208: '들', 209: '듬', 210: '듭', 211: '듯', 212: '등', 213: '듸', 214: '디', 215: '딘', 216: '딱', 217: '땅', 218: '때', 219: '땐', 220: '땡', 221: '떠', 222: '떡', 223: '떨', 224: '떵', 225: '떻', 226: '또', 227: '똑', 228: '똔', 229: '똘', 230: '똠', 231: '똣', 232: '똥', 233: '뚜', 234: '뚝', 235: '뚱', 236: '뜨', 237: '뜩', 238: '뜰', 239: '뜻', 240: '띠', 241: '라', 242: '락', 243: '란', 244: '람', 245: '랍', 246: '랏', 247: '랐', 248: '랑', 249: '래', 250: '랜', 251: '랭', 252: '량', 253: '러', 254: '럭', 255: '런', 256: '럽', 257: '렀', 258: '렁', 259: '레', 260: '렌', 261: '렝', 262: '려', 263: '련', 264: '렴', 265: '렵', 266: '령', 267: '로', 268: '록', 269: '롬', 270: '롱', 271: '루', 272: '룩', 273: '룬', 274: '룸', 275: '룹', 276: '룽', 277: '르', 278: '른', 279: '를', 280: '름', 281: '릅', 282: '릇', 283: '리', 284: '린', 285: '릴', 286: '림', 287: '립', 288: '링', 289: '마', 290: '막', 291: '만', 292: '많', 293: '말', 294: '맑', 295: '맙', 296: '맛', 297: '망', 298: '맞', 299: '맥', 300: '맨', 301: '맹', 302: '머', 303: '먹', 304: '멀', 305: '멋', 306: '멍', 307: '메', 308: '멕', 309: '멘', 310: '멜', 311: '멩', 312: '면', 313: '명', 314: '모', 315: '목', 316: '몬', 317: '몰', 318: '몸', 319: '못', 320: '몽', 321: '무', 322: '묵', 323: '묶', 324: '문', 325: '물', 326: '뭇', 327: '뭉', 328: '뭐', 329: '미', 330: '민', 331: '믿', 332: '밀', 333: '밑', 334: '바', 335: '박', 336: '반', 337: '발', 338: '밤', 339: '밥', 340: '밧', 341: '방', 342: '밭', 343: '배', 344: '백', 345: '밸', 346: '뱁', 347: '뱃', 348: '뱅', 349: '버', 350: '벅', 351: '벌', 352: '범', 353: '벗', 354: '벙', 355: '베', 356: '벡', 357: '벤', 358: '벨', 359: '벳', 360: '벵', 361: '별', 362: '병', 363: '보', 364: '복', 365: '본', 366: '볼', 367: '봅', 368: '봉', 369: '봐', 370: '봔', 371: '봥', 372: '뵈', 373: '부', 374: '북', 375: '분', 376: '불', 377: '붑', 378: '붓', 379: '붙', 380: '븐', 381: '비', 382: '빈', 383: '빌', 384: '빗', 385: '빙', 386: '빠', 387: '빡', 388: '뺄', 389: '뻘', 390: '뽀', 391: '뽈', 392: '뿌', 393: '뿐', 394: '쁜', 395: '삐', 396: '삔', 397: '사', 398: '삭', 399: '산', 400: '살', 401: '삶', 402: '삼', 403: '삽', 404: '상', 405: '새', 406: '샛', 407: '생', 408: '서', 409: '석', 410: '섞', 411: '선', 412: '설', 413: '섭', 414: '섯', 415: '성', 416: '세', 417: '센', 418: '셔', 419: '셩', 420: '소', 421: '속', 422: '손', 423: '솔', 424: '솖', 425: '솜', 426: '솟', 427: '송', 428: '쇠', 429: '수', 430: '숙', 431: '순', 432: '숟', 433: '술', 434: '숨', 435: '숭', 436: '쉐', 437: '쉬', 438: '쉰', 439: '스', 440: '슨', 441: '슬', 442: '슴', 443: '승', 444: '시', 445: '식', 446: '신', 447: '실', 448: '심', 449: '십', 450: '싯', 451: '싱', 452: '싶', 453: '싸', 454: '싼', 455: '쌍', 456: '써', 457: '썰', 458: '썸', 459: '썹', 460: '썼', 461: '쎄', 462: '쏘', 463: '쏟', 464: '쏠', 465: '쑤', 466: '쓰', 467: '쓸', 468: '씀', 469: '씌', 470: '씨', 471: '씩', 472: '씬', 473: '씸', 474: '씻', 475: '아', 476: '악', 477: '안', 478: '앉', 479: '않', 480: '알', 481: '암', 482: '앗', 483: '았', 484: '앙', 485: '앚', 486: '앞', 487: '애', 488: '액', 489: '앤', 490: '앨', 491: '야', 492: '약', 493: '얄', 494: '양', 495: '어', 496: '억', 497: '언', 498: '얼', 499: '엄', 500: '엇', 501: '었', 502: '엉', 503: '에', 504: '엔', 505: '엥', 506: '여', 507: '역', 508: '연', 509: '열', 510: '염', 511: '영', 512: '옆', 513: '예', 514: '옌', 515: '옛', 516: '오', 517: '옥', 518: '온', 519: '올', 520: '옴', 521: '옵', 522: '옷', 523: '와', 524: '왁', 525: '완', 526: '왐', 527: '왓', 528: '왔', 529: '왕', 530: '외', 531: '왼', 532: '요', 533: '욕', 534: '용', 535: '우', 536: '욱', 537: '운', 538: '울', 539: '움', 540: '웁', 541: '웃', 542: '워', 543: '원', 544: '월', 545: '웠', 546: '웡', 547: '위', 548: '윌', 549: '유', 550: '융', 551: '으', 552: '은', 553: '을', 554: '음', 555: '읍', 556: '읏', 557: '의', 558: '이', 559: '인', 560: '일', 561: '잃', 562: '임', 563: '입', 564: '잇', 565: '있', 566: '자', 567: '작', 568: '잘', 569: '잠', 570: '잡', 571: '장', 572: '재', 573: '잰', 574: '쟁', 575: '저', 576: '전', 577: '절', 578: '젊', 579: '점', 580: '접', 581: '정', 582: '제', 583: '젠', 584: '젯', 585: '젱', 586: '져', 587: '졈', 588: '졌', 589: '졍', 590: '조', 591: '족', 592: '존', 593: '졸', 594: '좀', 595: '좁', 596: '종', 597: '좋', 598: '죄', 599: '죙', 600: '주', 601: '죽', 602: '준', 603: '줄', 604: '줌', 605: '줍', 606: '중', 607: '줘', 608: '줨', 609: '줬', 610: '쥐', 611: '즙', 612: '지', 613: '직', 614: '진', 615: '질', 616: '짐', 617: '집', 618: '짓', 619: '짚', 620: '짝', 621: '째', 622: '짹', 623: '쩌', 624: '쪼', 625: '쪽', 626: '쫄', 627: '쭈', 628: '찌', 629: '찍', 630: '차', 631: '착', 632: '찾', 633: '채', 634: '처', 635: '척', 636: '천', 637: '첩', 638: '청', 639: '체', 640: '쳉', 641: '쳐', 642: '쳤', 643: '초', 644: '촌', 645: '촐', 646: '촘', 647: '촙', 648: '촛', 649: '총', 650: '추', 651: '춘', 652: '춤', 653: '췀', 654: '취', 655: '치', 656: '친', 657: '칠', 658: '칩', 659: '칭', 660: '카', 661: '칼', 662: '캐', 663: '캠', 664: '커', 665: '컨', 666: '케', 667: '켜', 668: '켬', 669: '코', 670: '콥', 671: '콩', 672: '콰', 673: '쿠', 674: '쿨', 675: '퀴', 676: '크', 677: '큰', 678: '큼', 679: '큽', 680: '키', 681: '타', 682: '탁', 683: '탄', 684: '탈', 685: '탕', 686: '태', 687: '택', 688: '탱', 689: '터', 690: '턱', 691: '털', 692: '텃', 693: '텅', 694: '테', 695: '텔', 696: '텡', 697: '토', 698: '톨', 699: '통', 700: '톼', 701: '투', 702: '퉁', 703: '트', 704: '특', 705: '튼', 706: '틀', 707: '틉', 708: '티', 709: '틴', 710: '파', 711: '판', 712: '팔', 713: '팝', 714: '팡', 715: '패', 716: '팽', 717: '펀', 718: '페', 719: '펜', 720: '펭', 721: '편', 722: '폐', 723: '포', 724: '폭', 725: '폿', 726: '퐁', 727: '푸', 728: '푼', 729: '풀', 730: '품', 731: '풍', 732: '프', 733: '픈', 734: '픔', 735: '피', 736: '핀', 737: '핏', 738: '하', 739: '한', 740: '할', 741: '함', 742: '합', 743: '항', 744: '해', 745: '핵', 746: '핸', 747: '햄', 748: '햇', 749: '했', 750: '행', 751: '허', 752: '헌', 753: '헐', 754: '험', 755: '헙', 756: '헴', 757: '혈', 758: '호', 759: '혼', 760: '홀', 761: '홈', 762: '홉', 763: '홍', 764: '화', 765: '확', 766: '황', 767: '훌', 768: '훼', 769: '휘', 770: '흐', 771: '흘', 772: '흙', 773: '흥', 774: '흰', 775: '히', 776: '힌'}\n","{0: '\\t', 1: '\\n', 2: ' ', 3: '!', 4: \"'\", 5: ',', 6: '.', 7: '0', 8: '1', 9: '3', 10: '4', 11: '5', 12: '?', 13: '`', 14: 'g', 15: 'k', 16: '가', 17: '각', 18: '간', 19: '갈', 20: '감', 21: '갑', 22: '값', 23: '갓', 24: '갔', 25: '강', 26: '같', 27: '개', 28: '걀', 29: '거', 30: '걱', 31: '건', 32: '걷', 33: '걸', 34: '검', 35: '겁', 36: '것', 37: '겋', 38: '게', 39: '겠', 40: '겨', 41: '결', 42: '겼', 43: '경', 44: '계', 45: '고', 46: '곡', 47: '곧', 48: '곰', 49: '곱', 50: '곳', 51: '공', 52: '과', 53: '관', 54: '광', 55: '괭', 56: '교', 57: '구', 58: '국', 59: '군', 60: '굴', 61: '굵', 62: '굶', 63: '굼', 64: '굿', 65: '궁', 66: '궈', 67: '귀', 68: '귓', 69: '그', 70: '근', 71: '글', 72: '금', 73: '급', 74: '긋', 75: '기', 76: '긴', 77: '긷', 78: '길', 79: '김', 80: '깊', 81: '까', 82: '깐', 83: '깝', 84: '깨', 85: '깬', 86: '꺼', 87: '껏', 88: '께', 89: '꼬', 90: '꼭', 91: '꼼', 92: '꼽', 93: '꽁', 94: '꽂', 95: '꽃', 96: '꽉', 97: '꾀', 98: '꾸', 99: '꾼', 100: '꿀', 101: '꿈', 102: '뀐', 103: '끄', 104: '끈', 105: '끌', 106: '끓', 107: '끔', 108: '끗', 109: '끝', 110: '끼', 111: '낀', 112: '나', 113: '난', 114: '날', 115: '남', 116: '납', 117: '낫', 118: '났', 119: '낮', 120: '낳', 121: '내', 122: '낼', 123: '냐', 124: '냥', 125: '너', 126: '넓', 127: '넘', 128: '넣', 129: '네', 130: '녀', 131: '녁', 132: '년', 133: '녕', 134: '노', 135: '놀', 136: '놈', 137: '놓', 138: '누', 139: '눈', 140: '느', 141: '늑', 142: '는', 143: '늘', 144: '늙', 145: '늦', 146: '늬', 147: '니', 148: '닌', 149: '닐', 150: '님', 151: '닙', 152: '다', 153: '닥', 154: '단', 155: '달', 156: '닭', 157: '닮', 158: '담', 159: '답', 160: '닷', 161: '당', 162: '대', 163: '더', 164: '덕', 165: '던', 166: '덜', 167: '덟', 168: '덩', 169: '덮', 170: '데', 171: '덴', 172: '도', 173: '독', 174: '돈', 175: '돌', 176: '돔', 177: '동', 178: '돼', 179: '됐', 180: '되', 181: '된', 182: '될', 183: '됩', 184: '두', 185: '둑', 186: '둘', 187: '둠', 188: '둡', 189: '둣', 190: '둥', 191: '뒤', 192: '뒹', 193: '드', 194: '득', 195: '든', 196: '듣', 197: '들', 198: '듭', 199: '듯', 200: '등', 201: '디', 202: '따', 203: '딸', 204: '땀', 205: '땅', 206: '땋', 207: '때', 208: '땠', 209: '떠', 210: '떡', 211: '떤', 212: '떨', 213: '떵', 214: '떻', 215: '뗀', 216: '또', 217: '똑', 218: '똥', 219: '뚝', 220: '뚫', 221: '뚱', 222: '뛰', 223: '뛴', 224: '뜨', 225: '뜬', 226: '뜻', 227: '띠', 228: '라', 229: '락', 230: '란', 231: '람', 232: '랍', 233: '랐', 234: '랑', 235: '랗', 236: '래', 237: '랜', 238: '랬', 239: '랭', 240: '랴', 241: '러', 242: '런', 243: '럼', 244: '럽', 245: '렀', 246: '렁', 247: '렇', 248: '레', 249: '려', 250: '련', 251: '렴', 252: '렵', 253: '렸', 254: '례', 255: '로', 256: '록', 257: '롭', 258: '롱', 259: '루', 260: '룩', 261: '르', 262: '른', 263: '를', 264: '름', 265: '릅', 266: '릇', 267: '릎', 268: '리', 269: '린', 270: '릴', 271: '림', 272: '립', 273: '마', 274: '막', 275: '만', 276: '많', 277: '말', 278: '맑', 279: '맙', 280: '맛', 281: '망', 282: '맞', 283: '매', 284: '맨', 285: '맴', 286: '맷', 287: '맹', 288: '맺', 289: '머', 290: '먹', 291: '먼', 292: '멋', 293: '멍', 294: '멓', 295: '메', 296: '멘', 297: '멜', 298: '며', 299: '멱', 300: '면', 301: '명', 302: '모', 303: '목', 304: '몫', 305: '몸', 306: '못', 307: '무', 308: '묶', 309: '문', 310: '물', 311: '뭇', 312: '뭐', 313: '뭔', 314: '뭘', 315: '믄', 316: '미', 317: '믿', 318: '밀', 319: '밑', 320: '바', 321: '박', 322: '반', 323: '받', 324: '발', 325: '밝', 326: '밟', 327: '밤', 328: '밥', 329: '방', 330: '밭', 331: '배', 332: '백', 333: '뱀', 334: '뱃', 335: '버', 336: '벅', 337: '번', 338: '벌', 339: '범', 340: '법', 341: '벗', 342: '벙', 343: '베', 344: '벵', 345: '벼', 346: '변', 347: '별', 348: '병', 349: '볕', 350: '보', 351: '복', 352: '본', 353: '볼', 354: '봅', 355: '봐', 356: '봤', 357: '부', 358: '북', 359: '분', 360: '불', 361: '붓', 362: '붙', 363: '비', 364: '빈', 365: '빌', 366: '빗', 367: '빙', 368: '빛', 369: '빠', 370: '빨', 371: '뺨', 372: '뻘', 373: '뼈', 374: '뿌', 375: '뿐', 376: '쁘', 377: '쁜', 378: '삐', 379: '사', 380: '삭', 381: '삯', 382: '산', 383: '살', 384: '삶', 385: '삼', 386: '삽', 387: '삿', 388: '상', 389: '새', 390: '색', 391: '샛', 392: '생', 393: '서', 394: '섞', 395: '선', 396: '설', 397: '섭', 398: '섯', 399: '성', 400: '세', 401: '센', 402: '셔', 403: '셨', 404: '소', 405: '속', 406: '손', 407: '솔', 408: '송', 409: '쇠', 410: '수', 411: '순', 412: '숟', 413: '술', 414: '숨', 415: '숫', 416: '숭', 417: '쉐', 418: '스', 419: '슨', 420: '슬', 421: '슴', 422: '습', 423: '승', 424: '시', 425: '식', 426: '신', 427: '실', 428: '싫', 429: '심', 430: '십', 431: '싶', 432: '싸', 433: '쌀', 434: '쌌', 435: '쌍', 436: '쌓', 437: '써', 438: '썩', 439: '썰', 440: '썹', 441: '쎄', 442: '쏟', 443: '쑥', 444: '쓰', 445: '쓸', 446: '씀', 447: '씨', 448: '씩', 449: '씬', 450: '아', 451: '안', 452: '앉', 453: '않', 454: '알', 455: '암', 456: '앗', 457: '았', 458: '앞', 459: '애', 460: '액', 461: '야', 462: '약', 463: '얀', 464: '얇', 465: '양', 466: '얘', 467: '어', 468: '억', 469: '언', 470: '얼', 471: '엄', 472: '없', 473: '엇', 474: '었', 475: '엉', 476: '엊', 477: '엌', 478: '에', 479: '엔', 480: '여', 481: '엮', 482: '연', 483: '열', 484: '염', 485: '였', 486: '영', 487: '옆', 488: '예', 489: '옛', 490: '오', 491: '옥', 492: '온', 493: '올', 494: '옮', 495: '옵', 496: '옷', 497: '와', 498: '왁', 499: '왔', 500: '왕', 501: '왜', 502: '외', 503: '왼', 504: '요', 505: '욕', 506: '용', 507: '우', 508: '운', 509: '울', 510: '움', 511: '웁', 512: '웃', 513: '워', 514: '원', 515: '월', 516: '웠', 517: '위', 518: '윗', 519: '유', 520: '으', 521: '은', 522: '을', 523: '음', 524: '읍', 525: '의', 526: '이', 527: '익', 528: '인', 529: '일', 530: '잃', 531: '입', 532: '있', 533: '자', 534: '작', 535: '잔', 536: '잖', 537: '잘', 538: '잠', 539: '잡', 540: '장', 541: '재', 542: '쟁', 543: '저', 544: '적', 545: '전', 546: '절', 547: '젊', 548: '점', 549: '접', 550: '젓', 551: '정', 552: '제', 553: '져', 554: '졌', 555: '조', 556: '족', 557: '졸', 558: '좀', 559: '종', 560: '좋', 561: '죄', 562: '죠', 563: '주', 564: '죽', 565: '준', 566: '줄', 567: '줌', 568: '줍', 569: '중', 570: '줘', 571: '줬', 572: '쥐', 573: '즉', 574: '즐', 575: '즙', 576: '지', 577: '진', 578: '질', 579: '짐', 580: '집', 581: '짓', 582: '짚', 583: '짜', 584: '짝', 585: '째', 586: '짹', 587: '쨍', 588: '쩌', 589: '쩔', 590: '쪽', 591: '찌', 592: '찍', 593: '찐', 594: '찡', 595: '차', 596: '착', 597: '찬', 598: '찮', 599: '참', 600: '찹', 601: '찾', 602: '채', 603: '챙', 604: '처', 605: '척', 606: '천', 607: '철', 608: '첩', 609: '청', 610: '체', 611: '쳐', 612: '쳤', 613: '초', 614: '촉', 615: '촌', 616: '총', 617: '추', 618: '춤', 619: '치', 620: '친', 621: '칠', 622: '칡', 623: '침', 624: '카', 625: '칼', 626: '캄', 627: '커', 628: '켜', 629: '켠', 630: '코', 631: '콤', 632: '콩', 633: '쾌', 634: '크', 635: '큰', 636: '큼', 637: '키', 638: '타', 639: '탄', 640: '탕', 641: '태', 642: '터', 643: '턱', 644: '털', 645: '텃', 646: '텅', 647: '테', 648: '텐', 649: '텔', 650: '통', 651: '투', 652: '퉁', 653: '퉈', 654: '특', 655: '틀', 656: '틈', 657: '티', 658: '파', 659: '팍', 660: '팔', 661: '팡', 662: '팥', 663: '패', 664: '팽', 665: '편', 666: '평', 667: '포', 668: '폭', 669: '푸', 670: '푼', 671: '풀', 672: '품', 673: '풍', 674: '프', 675: '픈', 676: '픔', 677: '피', 678: '핀', 679: '하', 680: '학', 681: '한', 682: '할', 683: '함', 684: '합', 685: '항', 686: '해', 687: '햇', 688: '했', 689: '향', 690: '허', 691: '헌', 692: '험', 693: '헤', 694: '현', 695: '혈', 696: '형', 697: '호', 698: '혼', 699: '홀', 700: '화', 701: '확', 702: '황', 703: '횃', 704: '후', 705: '훔', 706: '흉', 707: '흐', 708: '흔', 709: '흘', 710: '흙', 711: '흥', 712: '흩', 713: '희', 714: '흰', 715: '히', 716: '힘'}\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"sNknhamg35mS","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"5e0ee1da-e89e-4873-8272-13823dae8617","executionInfo":{"status":"ok","timestamp":1582017367269,"user_tz":-540,"elapsed":2030,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 학습에 사용할 데이터를 담을 3차원 배열\n","encoder_input_data = np.zeros(\n","    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n","    dtype='float32')\n","decoder_input_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","decoder_target_data = np.zeros(\n","    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n","    dtype='float32')\n","\n","# 문장을 문자 단위로 원 핫 인코딩하면서 학습용 데이터를 만듬\n","for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n","    for t, char in enumerate(input_text):\n","        encoder_input_data[i, t, input_token_index[char]] = 1.\n","    for t, char in enumerate(target_text):\n","        decoder_input_data[i, t, target_token_index[char]] = 1.\n","        if t > 0:\n","            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n","\n","print(encoder_input_data[:3])\n","print(decoder_input_data[:3])\n","print(decoder_target_data[:3])"],"execution_count":9,"outputs":[{"output_type":"stream","text":["[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]]\n","[[[1. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]\n","\n"," [[1. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]\n","\n"," [[1. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]]\n","[[[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]\n","\n"," [[0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  ...\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]\n","  [0. 0. 0. ... 0. 0. 0.]]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9u82scWh5KSn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":325},"outputId":"20fd6ab5-0433-4988-eaf4-295a09ff515d","executionInfo":{"status":"ok","timestamp":1582017368753,"user_tz":-540,"elapsed":929,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 인코더 input                 제주어 음절수 최대길이:165. 제주어 구성하는 음절수:777\n","encoder_inputs = layers.Input(shape=(max_encoder_seq_length, num_encoder_tokens))\n","print(encoder_inputs.shape)\n","\n","#input 인스턴스 해주고 GRU 모델로 encoder 만들어줌\n","encoder = layers.GRU(latent_dim, dropout=0.25, recurrent_dropout=0.25, return_sequences=True, return_state=True)\n","\n","\n","# latent_dim = 256  # 음절이 워낙 많으니까 밀집벡터로 만들어서 인코더에 이용할것.\n","\n","\n","\n","# GRU 인코더 1층짜리 만듦. 제주어 데이터 넣어서 히든셀 state 와 output 얻음\n","encoder_outputs, state_h = encoder(encoder_inputs)\n","\n","print('\\n\\nencoder output 결과 밀집벡터 256차원으로 나옴',encoder_outputs.shape)\n","print('마지막 h 에서 나온 output', state_h.shape)\n","# dropout 전\n","# encoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)"],"execution_count":10,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","(?, 165, 777)\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n","\n","\n","encoder output 결과 밀집벡터 256차원으로 나옴 (?, ?, 256)\n","마지막 h 에서 나온 output (?, 256)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"B6q8GHNg5KVU","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":107},"outputId":"27d58716-2095-428f-f79e-734d6ac24bc2","executionInfo":{"status":"ok","timestamp":1582017371974,"user_tz":-540,"elapsed":1698,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 디코더 input                 표준어 음절수 최대길이:183  표준어 구성하는 음절수:717\n","decoder_inputs = layers.Input(shape=(max_decoder_seq_length, num_decoder_tokens))\n","print(decoder_inputs.shape)\n","#input 인스턴스 해주고 GRU 모델로 decoder 만들어줌\n","decoder = layers.GRU(latent_dim,dropout=0.25,recurrent_dropout=0.25, return_sequences=True, return_state=True)\n","\n","\n","\n","\n","\n","\n","\n","# 제주어 인코더에 들어가서 나온 히든셀state 를 받아서 decoder로 들어감. attention 망을 거쳐서 hs 행렬벡터로 받아야하는데??\n","# 디코더로 들어가는 input 은 표준어번역 문장 : 인코더에서 나온 hidden state 와 decoder GRU 망을 거쳐서 번역기 돌아감\n","decoder_outputs, _ = decoder(decoder_inputs, initial_state=state_h) \n","\n","print('\\n\\ndecoder output 결과 밀집벡터 256차원으로 나옴',decoder_outputs.shape)\n","print('마지막 dh 에서 나온 output', state_h.shape)\n","\n","# dropout 전\n","# decoder = layers.GRU(latent_dim, return_sequences=True, return_state=True)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["(?, 183, 717)\n","\n","\n","decoder output 결과 밀집벡터 256차원으로 나옴 (?, ?, 256)\n","마지막 dh 에서 나온 output (?, 256)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"_p22zvIQLqQd","colab_type":"text"},"source":["https://neurowhai.tistory.com/292\n","\n","# 이사람 홈페이지 순서대로 다시 짜보자.\n","\n","\n","# attention 생성\n","'''\n","어텐션의 기본 아이디어는 디코더에서 출력 단어를 예측하는 매 시점(time step)마다, \n","인코더에서의 전체 입력 문장을 다시 한 번 참고한다는 점입니다. \n","단, 전체 입력 문장을 전부 다 동일한 비율로 참고하는 것이 아니라, \n","해당 시점에서 예측해야할 단어와 연관이 있는 입력 단어 부분을 좀 더 \n","집중(attention)해서 보게 됩니다.\n","'''"]},{"cell_type":"code","metadata":{"id":"T-0HRu-e58IP","colab_type":"code","colab":{}},"source":["def RepeatVectorLayer(rep, axis):\n","  return layers.Lambda(lambda x: K.repeat_elements(K.expand_dims(x, axis), rep, axis),\n","                      lambda x: tuple((x[0],) + x[1:axis] + (rep,) + x[axis:]))\n","  \n","# repeat_elements 함수는 1차원에 벡터에 b=[01] 이 있다고 가정하면\n","# repeat_elements(b, rep=2, axis=0) 이렇게 적으면 행으로 \n","# 0 0\n","# 1 1\n","# 이런식으로 증가\n","\n","\n","# \n","# K.expand_dims 은\n","# K.expand_dims(n,0) 이렇게적으면 2*2 행렬이 1*2*2 행렬로\n","# K.expand_dims(n,1) 이렇게적으면 2*2 행렬이 2*1*2 행렬로 차원을 증가시켜줌\n","# 기존엔 reshape 으로 하던걸 텐서에서는 K.expand_dims를 사용\n","#\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3RvVo3xk7urW","colab_type":"text"},"source":["# repeat함수랑  expand_dims 함수써서 텐서의 차원을 맞춰줌\n","\n","\n","- def RepeatVectorLayer(rep, axis):\n","\n","repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n","\n","rep =인코더 음절구성 최대문장길이, axis=2\n","\n","- def RepeatVectorLayer(rep, axis):\n","\n","repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1)\n","\n","rep = 디코더 음절구성 최대문장길이,  axis =1  \n","\n","\n","\n","\n","\n","---\n","\n","\n","\n","즉 2번쨰 차원에 1차원을 추가한거고\n","max_decoder_seq_length 값 만큼 차원 증가한거같네요\n","\n","\n","\n","위에 책내용하고 expand_dims 함수 써서 텐서 차원 증가시키면서 값들을 \n","max_decoder_seq_length 이걸로 가득채우는거같네용"]},{"cell_type":"code","metadata":{"id":"jnqddXYx8rSo","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"d451a5fb-8a74-4b9b-d264-b59084b92950","executionInfo":{"status":"ok","timestamp":1582017378764,"user_tz":-540,"elapsed":1088,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 영택이 소스 아님. \n","# 어텐션 메커니즘\n","\n","repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2) # 인코더에 들어간 제주어최대문장길이를 넣어주고 4차원 벡터로 만듦\n","repeat_d = repeat_d_layer(decoder_outputs)                    # 디코더를 통해서 나온 outputs : dh1\n","print('제주어 음절구성 최대길이, 2차원에 넣어주고 decoder_outputs : dh 를 행렬곱을 위해 repeat',repeat_d.shape) \n","# 4차원 텐서로 바꿔줌. K.repeat_elements(K.expand_dims(x, axis), 최대문장길이 165, axis=2\n","\n","\n","repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1) # 디코더에 들어가는 표준어 최대문장길이, 4차원으로 만들어줌\n","repeat_e = repeat_e_layer(encoder_outputs) # encoder output : 제주어 : GRU 망을 거쳐서 나온 값....:  h1.h2.....ht\n","\n","print('번역표준어 음절구성 최대길이, 2차원에 넣어주고 encoder_outputs : h 를 행렬곱을 위해 repeat',repeat_e.shape) \n","\n","# 제주어와 번역표준어 음절최대길이를 2차원, 3차원에 넣기 위해서 concat ???\n","\n","\n","\n","\n","\n","\n","# layers.Concatenate는 입력 목록을 연결하는 계층\n","# 연결 축을 제외하고 모두 동일한 모양의 텐서 목록을 입력으로 사용하고  모든 입력을  연결한 단일 텐서를 반환합니다.\n","\n","concat_for_score_layer = layers.Concatenate(axis = -1)\n","concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n","print('\\n\\n제주어 음절최대길이, 표준어번역 음절최대길이 concat, 총 512밀집벡터 합쳐짐',concat_for_score.shape)\n","\n","\n","\n","\n","\n","\n","'''왜 이렇게 둘을 연결시켜주는지 이해가 안가는데, '''"],"execution_count":13,"outputs":[{"output_type":"stream","text":["제주어 음절구성 최대길이, 2차원에 넣어주고 decoder_outputs : dh 를 행렬곱을 위해 repeat (?, ?, 165, 256)\n","번역표준어 음절구성 최대길이, 2차원에 넣어주고 encoder_outputs : h 를 행렬곱을 위해 repeat (?, 183, ?, 256)\n","\n","\n","제주어 음절최대길이, 표준어번역 음절최대길이 concat, 총 512밀집벡터 합쳐짐 (?, 183, 165, 512)\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["'왜 이렇게 둘을 연결시켜주는지 이해가 안가는데, '"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"markdown","metadata":{"id":"slrq5TADDb-u","colab_type":"text"},"source":["\n","# 왜??????? 4차원으로 만들어서 제주어 음절최대길이, 표준어번역 음절최대길이 concat (?, 183, 165, 512)\n","\n","![대체 텍스트](https://www.eksss.org/journal/pss/pss-11-1/gif/pss-11-1-41-g1.gif)\n","\n","\n","\n","# 내가 아는 concat 은  Attention 을 통해서 각 attention score 구해지고 softmax 로 distribution 과정후 attention weight =at 를 구해서 각각의 h1,h2,h3,,, 이전에 나온 값들과 내적을 통해 가중치합을 = context vectore (그림에서 r) 로 만들고 Decoder 를 통해서 나온output (그림에서 c)을 연결해주고 다시 인코더로 들어감.."]},{"cell_type":"code","metadata":{"id":"MjRj7b6a_LYy","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"df3b1404-c32e-4f4c-8491-48099aa07230","executionInfo":{"status":"ok","timestamp":1582017381248,"user_tz":-540,"elapsed":819,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 내가 아는 attention 망의 concat  =>  tanh(   Fully-connected(h1,h2,,,,ht) + FC(decoder h1)   )\n","# https://www.youtube.com/watch?v=WsQLdu2JMgI&t=38s\n","\n","# 각각의 히든셀 값을 FC 만들고 디코더 이전output 과 합쳐서 tanh 계산해줘야함\n","\n","# Dense 층으로 FC 완전연결계층 생성. tanh 활성화 함수 사용함.\n","# 여기서는 밀집벡터 //2 나눠준 값\n","# 256 //2 = 128 차원으로 줄이고 => 다음 Dense 층에서 1차원으로 Fully-connected 생성....\n","dense1_t_score_layer = layers.Dense(latent_dim // 2, activation='tanh') \n","dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n","# 0-1 사이 정규화\n","\n","dense1_score = dense1_score_layer(concat_for_score) # concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n","print('256차원 (제주어,표준어 최대길이 반영한) 밀집벡터 1/2 사이즈 줄임\\t', dense1_score.shape)\n","\n","'''왜 두개의 repeat 디코더 아웃풋과 repeat 인코더 아웃풋을 합쳐준 concat 레이어를 넣어주지? \n","마지막 결과 (?, 183, 165) 를 만들어주기 위해서.....? 왜 두개의 최대길이를 넣어야하는지 모르겠다...'''\n","\n","\n","dense2_t_score_layer = layers.Dense(1) # attention 정규화를 거쳐서 나온 완전연결계층 : 1차원\n","dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer) \n","\n","\n","dense2_score = dense2_score_layer(dense1_score) \n","print('\\n\\n1차원 FC 완전연결\\t',dense2_score.shape)\n","dense2_score = layers.Reshape((max_decoder_seq_length, max_encoder_seq_length))(dense2_score)\n","                           # 표준어 문장 음절최대길이, 제주어 문장 음절최대길이  # 뒤에 (dense2_score)= 이건 input\n","\n","                           # reshape( (165,183) ) : dense2_score 를 (165, 183) 모양으로 재배치 => 3차원으로 바꿔줌...?\n","print('Reshape 모양 재배치\\t',dense2_score.shape)\n","\n","\n","# tanh 활성화 함수를 통해서 attention score 구했고\n","# fully-connected 되었으니 이제  softmax 함수를 들어가서 확률로 바꿀차례\n","\n","softmax_score_layer = layers.Softmax(axis = -1) \n","softmax_score = softmax_score_layer(dense2_score) # FC 완전연결층 넣어서 softmax 통과시킴.\n","print('attention score + softmax = 확률 정규화 결과', softmax_score.shape)\n","# attention score 구해지면 바로 distribution 정규화 시켜주고 "],"execution_count":14,"outputs":[{"output_type":"stream","text":["256차원 (제주어,표준어 최대길이 반영한) 밀집벡터 1/2 사이즈 줄임\t (?, 183, 165, 128)\n","\n","\n","1차원 FC 완전연결\t (?, 183, 165, 1)\n","Reshape 모양 재배치\t (?, 183, 165)\n","attention score + softmax = 확률 정규화 결과 (?, 183, 165)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"JLkEWonzdfEK","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":71},"outputId":"133b5cd9-bafe-416e-e5d5-c851a5042e5f","executionInfo":{"status":"ok","timestamp":1582017384130,"user_tz":-540,"elapsed":1092,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 왜 다시 256차원 밀집벡터 embedding 차원을 사용할까????\n","\n","repeat_score_layer = RepeatVectorLayer(latent_dim, 2) \n","repeat_score = repeat_score_layer(softmax_score) \n","print(\"attention weight : 256밀집벡터를 2차원에 끼워넣고 확률 attetion_softmax_score를 반복시킴\",repeat_score.shape)\n","\n","# attention weight 을 구했으니 hidden state 값들과 내적을 진행하기 위해. repeat 함수를 이용해서 hs 만듦\n","print('\\nhs 값이 256밀집벡터로 embeding 되었기때문에')\n"],"execution_count":15,"outputs":[{"output_type":"stream","text":["attention weight : 256밀집벡터를 2차원에 끼워넣고 확률 attetion_softmax_score를 반복시킴 (?, 183, 256, 165)\n","\n","hs 값이 256밀집벡터로 embeding 되었기때문에\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kBuenTodRg7v","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":163},"outputId":"4362326b-32a4-488d-b9a9-50e08fe960d4","executionInfo":{"status":"ok","timestamp":1582017387347,"user_tz":-540,"elapsed":944,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["print('encoder_outputs ',encoder_outputs.shape)\n","permute_e = layers.Permute((2, 1))(encoder_outputs) \n","print('repeat  hs 행렬벡터 : 행렬곱을 위해서 shape 치환',permute_e.shape)\n","\n","\n","repeat_e_layer = RepeatVectorLayer(max_decoder_seq_length, 1) \n","repeat_e = repeat_e_layer(permute_e) \n","print('위의 attention weight과 모양 맞춰서 decoder 최대길이 repeat',repeat_e.shape)\n","\n","\n","attended_mat_layer = layers.Multiply() \n","# 가중치들이 반복된 행렬과 encoder output이 반복된 행렬끼리 곱을 하게 해서\n","attended_mat = attended_mat_layer([repeat_score, repeat_e]) \n","# attention weight 생성.\n","context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1), lambda x: tuple(x[:-1])) \n","# 가중치합을 람다함수로 계산\n","\n","# context 벡터 생성!!!!\n","context = context_layer(attended_mat) \n","\n","print('\\n\\n',decoder_inputs.shape)\n","print('표준어길이에 맞춰진 decoder input 과 동일한 183길이, 717개 음절은 너무 길어서 256개로 밀집벡터음절 embedding ', context.shape)\n"],"execution_count":16,"outputs":[{"output_type":"stream","text":["encoder_outputs  (?, ?, 256)\n","repeat  hs 행렬벡터 : 행렬곱을 위해서 shape 치환 (?, 256, ?)\n","위의 attention weight과 모양 맞춰서 decoder 최대길이 repeat (?, 183, 256, ?)\n","\n","\n"," (?, 183, 717)\n","표준어길이에 맞춰진 decoder input 과 동일한 183길이, 717개 음절은 너무 길어서 256개로 밀집벡터음절 embedding  (?, 183, 256)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"On7433JTDZLJ","colab_type":"text"},"source":["케라스 Keras Documentation\n","\n","- keras.layers.Permute(dims)\n","\n","주어진 패턴에 따라서 input 차원을 치환한다.\n","\n","순환 신경망과 convnet을 함께 연결하는 경우에 유용합니다.\n","\n","\n","\n","\n","---\n","\n","\n","\n","\n","- model.add(Permute((2, 1), input_shape=(10, 64)))\n","\n","현재: model.output_shape == (None, 64, 10)\n","\n","`None`은 배치 차원"]},{"cell_type":"code","metadata":{"id":"c5Ha2MngWyf_","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":125},"outputId":"4908f307-2b65-483e-8905-75d202766b88","executionInfo":{"status":"ok","timestamp":1582017390315,"user_tz":-540,"elapsed":1087,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 인코더 attention 망을 거쳐서 나온 attention 가중치합까지 다 반영하면 만들어지는게 context \n","\n","# context 와 decoder_outputs : dh1 을 더해서 다음 예측을 위한 context 벡터를 만든다.\n","print('decoder GRU 통과하면 embedding 밀집벡터 형태로 output',decoder_outputs.shape)\n","concat_context_layer = layers.Concatenate(axis=-1) \n","concat_context = concat_context_layer([context, decoder_outputs]) \n","print('256차원 밀집벡터 embedding을 연결시켜서 512차원 증가',concat_context.shape) \n","\n","# 똑같이 tanh 활성화 함수로 들어가서 attention score => distribution => attention weight => 가중치합.\n","\n","attention_dense_output_layer = layers.Dense(latent_dim, activation='tanh') \n","attention_output_layer = layers.TimeDistributed(attention_dense_output_layer) \n","attention_output = attention_output_layer(concat_context) \n","\n","print('\\n\\ndecoder 이전output 과 context vector가 tanh 함수에 의해 연산됨', attention_output.shape)\n","\n","decoder_dense = layers.Dense(num_decoder_tokens, activation='softmax') \n","decoder_outputs = decoder_dense(attention_output)\n","print('softmax 함수에 의해 확률값으로 반영해서 표준어 번역문장 음절에 맞춰서 예측값', decoder_outputs.shape )\n"],"execution_count":17,"outputs":[{"output_type":"stream","text":["decoder GRU 통과하면 embedding 밀집벡터 형태로 output (?, ?, 256)\n","256차원 밀집벡터 embedding을 연결시켜서 512차원 증가 (?, 183, 512)\n","\n","\n","decoder 이전output 과 context vector가 tanh 함수에 의해 연산됨 (?, 183, 256)\n","softmax 함수에 의해 확률값으로 반영해서 표준어 번역문장 음절에 맞춰서 예측값 (?, 183, 717)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Wj7PW6l6hyZp","colab_type":"text"},"source":["# 모델 생성"]},{"cell_type":"code","metadata":{"id":"Nx28LPpCh1rG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"305128fd-a24e-4641-acaa-b7c6dc65aa43","executionInfo":{"status":"ok","timestamp":1582017392802,"user_tz":-540,"elapsed":1106,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# Define the model that will turn\n","# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n","model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n","che = 'keras_model1.model'\n","point = ModelCheckpoint(filepath=che , monitor='val_loss', verbose=1, save_best_only=True)\n","early_stopping = EarlyStopping(monitor='val_loss', patience=100)\n","# Run training\n","model.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n","              metrics=['accuracy'])\n","model.summary()"],"execution_count":18,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n","\n","Model: \"model_1\"\n","__________________________________________________________________________________________________\n","Layer (type)                    Output Shape         Param #     Connected to                     \n","==================================================================================================\n","input_1 (InputLayer)            (None, 165, 777)     0                                            \n","__________________________________________________________________________________________________\n","input_2 (InputLayer)            (None, 183, 717)     0                                            \n","__________________________________________________________________________________________________\n","gru_1 (GRU)                     [(None, 165, 256), ( 794112      input_1[0][0]                    \n","__________________________________________________________________________________________________\n","gru_2 (GRU)                     [(None, 183, 256), ( 748032      input_2[0][0]                    \n","                                                                 gru_1[0][1]                      \n","__________________________________________________________________________________________________\n","lambda_1 (Lambda)               (None, 183, 165, 256 0           gru_2[0][0]                      \n","__________________________________________________________________________________________________\n","lambda_2 (Lambda)               (None, 183, 165, 256 0           gru_1[0][0]                      \n","__________________________________________________________________________________________________\n","concatenate_1 (Concatenate)     (None, 183, 165, 512 0           lambda_1[0][0]                   \n","                                                                 lambda_2[0][0]                   \n","__________________________________________________________________________________________________\n","time_distributed_1 (TimeDistrib (None, 183, 165, 128 65664       concatenate_1[0][0]              \n","__________________________________________________________________________________________________\n","time_distributed_2 (TimeDistrib (None, 183, 165, 1)  129         time_distributed_1[0][0]         \n","__________________________________________________________________________________________________\n","reshape_1 (Reshape)             (None, 183, 165)     0           time_distributed_2[0][0]         \n","__________________________________________________________________________________________________\n","softmax_1 (Softmax)             (None, 183, 165)     0           reshape_1[0][0]                  \n","__________________________________________________________________________________________________\n","permute_1 (Permute)             (None, 256, 165)     0           gru_1[0][0]                      \n","__________________________________________________________________________________________________\n","lambda_3 (Lambda)               (None, 183, 256, 165 0           softmax_1[0][0]                  \n","__________________________________________________________________________________________________\n","lambda_4 (Lambda)               (None, 183, 256, 165 0           permute_1[0][0]                  \n","__________________________________________________________________________________________________\n","multiply_1 (Multiply)           (None, 183, 256, 165 0           lambda_3[0][0]                   \n","                                                                 lambda_4[0][0]                   \n","__________________________________________________________________________________________________\n","lambda_5 (Lambda)               (None, 183, 256)     0           multiply_1[0][0]                 \n","__________________________________________________________________________________________________\n","concatenate_2 (Concatenate)     (None, 183, 512)     0           lambda_5[0][0]                   \n","                                                                 gru_2[0][0]                      \n","__________________________________________________________________________________________________\n","time_distributed_3 (TimeDistrib (None, 183, 256)     131328      concatenate_2[0][0]              \n","__________________________________________________________________________________________________\n","dense_4 (Dense)                 (None, 183, 717)     184269      time_distributed_3[0][0]         \n","==================================================================================================\n","Total params: 1,923,534\n","Trainable params: 1,923,534\n","Non-trainable params: 0\n","__________________________________________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jWQZw5DcisaA","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","config = tf.compat.v1.ConfigProto()\n","config.gpu_options.allow_growth = True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Mv7YWAfGh5v-","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f04b2ffb-8c3e-4c6c-82c9-3c3d93f8035b","executionInfo":{"status":"ok","timestamp":1582018761388,"user_tz":-540,"elapsed":1363589,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["history = model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n","                    batch_size=batch_size,\n","                    epochs=epochs,\n","                    validation_split=0.2,\n","                    verbose=1,callbacks=[point,early_stopping])\n","# Save model\n","model.save('s2s.h5')"],"execution_count":19,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3005: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","Train on 939 samples, validate on 235 samples\n","Epoch 1/100\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:197: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:207: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:216: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:223: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n","\n","939/939 [==============================] - 23s 25ms/step - loss: 0.3640 - acc: 0.0120 - val_loss: 0.5524 - val_acc: 0.0252\n","\n","Epoch 00001: val_loss improved from inf to 0.55241, saving model to keras_model1.model\n","Epoch 2/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.3078 - acc: 0.0127 - val_loss: 0.5501 - val_acc: 0.0252\n","\n","Epoch 00002: val_loss improved from 0.55241 to 0.55015, saving model to keras_model1.model\n","Epoch 3/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.3044 - acc: 0.0130 - val_loss: 0.5475 - val_acc: 0.0241\n","\n","Epoch 00003: val_loss improved from 0.55015 to 0.54749, saving model to keras_model1.model\n","Epoch 4/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2997 - acc: 0.0137 - val_loss: 0.5378 - val_acc: 0.0280\n","\n","Epoch 00004: val_loss improved from 0.54749 to 0.53782, saving model to keras_model1.model\n","Epoch 5/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2932 - acc: 0.0145 - val_loss: 0.5216 - val_acc: 0.0285\n","\n","Epoch 00005: val_loss improved from 0.53782 to 0.52159, saving model to keras_model1.model\n","Epoch 6/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2855 - acc: 0.0151 - val_loss: 0.5071 - val_acc: 0.0286\n","\n","Epoch 00006: val_loss improved from 0.52159 to 0.50715, saving model to keras_model1.model\n","Epoch 7/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2780 - acc: 0.0160 - val_loss: 0.4895 - val_acc: 0.0297\n","\n","Epoch 00007: val_loss improved from 0.50715 to 0.48946, saving model to keras_model1.model\n","Epoch 8/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2723 - acc: 0.0169 - val_loss: 0.4774 - val_acc: 0.0332\n","\n","Epoch 00008: val_loss improved from 0.48946 to 0.47737, saving model to keras_model1.model\n","Epoch 9/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2682 - acc: 0.0178 - val_loss: 0.4688 - val_acc: 0.0334\n","\n","Epoch 00009: val_loss improved from 0.47737 to 0.46876, saving model to keras_model1.model\n","Epoch 10/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2639 - acc: 0.0181 - val_loss: 0.4621 - val_acc: 0.0343\n","\n","Epoch 00010: val_loss improved from 0.46876 to 0.46213, saving model to keras_model1.model\n","Epoch 11/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2591 - acc: 0.0187 - val_loss: 0.4617 - val_acc: 0.0340\n","\n","Epoch 00011: val_loss improved from 0.46213 to 0.46174, saving model to keras_model1.model\n","Epoch 12/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2568 - acc: 0.0188 - val_loss: 0.4505 - val_acc: 0.0364\n","\n","Epoch 00012: val_loss improved from 0.46174 to 0.45046, saving model to keras_model1.model\n","Epoch 13/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2529 - acc: 0.0193 - val_loss: 0.4473 - val_acc: 0.0376\n","\n","Epoch 00013: val_loss improved from 0.45046 to 0.44726, saving model to keras_model1.model\n","Epoch 14/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2486 - acc: 0.0199 - val_loss: 0.4381 - val_acc: 0.0388\n","\n","Epoch 00014: val_loss improved from 0.44726 to 0.43814, saving model to keras_model1.model\n","Epoch 15/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2449 - acc: 0.0204 - val_loss: 0.4353 - val_acc: 0.0385\n","\n","Epoch 00015: val_loss improved from 0.43814 to 0.43532, saving model to keras_model1.model\n","Epoch 16/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2418 - acc: 0.0204 - val_loss: 0.4326 - val_acc: 0.0409\n","\n","Epoch 00016: val_loss improved from 0.43532 to 0.43256, saving model to keras_model1.model\n","Epoch 17/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2385 - acc: 0.0211 - val_loss: 0.4292 - val_acc: 0.0414\n","\n","Epoch 00017: val_loss improved from 0.43256 to 0.42922, saving model to keras_model1.model\n","Epoch 18/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2355 - acc: 0.0215 - val_loss: 0.4224 - val_acc: 0.0416\n","\n","Epoch 00018: val_loss improved from 0.42922 to 0.42239, saving model to keras_model1.model\n","Epoch 19/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2313 - acc: 0.0222 - val_loss: 0.4176 - val_acc: 0.0429\n","\n","Epoch 00019: val_loss improved from 0.42239 to 0.41759, saving model to keras_model1.model\n","Epoch 20/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2314 - acc: 0.0222 - val_loss: 0.4140 - val_acc: 0.0423\n","\n","Epoch 00020: val_loss improved from 0.41759 to 0.41405, saving model to keras_model1.model\n","Epoch 21/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2263 - acc: 0.0226 - val_loss: 0.4099 - val_acc: 0.0438\n","\n","Epoch 00021: val_loss improved from 0.41405 to 0.40992, saving model to keras_model1.model\n","Epoch 22/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.2225 - acc: 0.0233 - val_loss: 0.4085 - val_acc: 0.0437\n","\n","Epoch 00022: val_loss improved from 0.40992 to 0.40850, saving model to keras_model1.model\n","Epoch 23/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2200 - acc: 0.0235 - val_loss: 0.4037 - val_acc: 0.0448\n","\n","Epoch 00023: val_loss improved from 0.40850 to 0.40367, saving model to keras_model1.model\n","Epoch 24/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2164 - acc: 0.0244 - val_loss: 0.4045 - val_acc: 0.0444\n","\n","Epoch 00024: val_loss did not improve from 0.40367\n","Epoch 25/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2137 - acc: 0.0245 - val_loss: 0.4018 - val_acc: 0.0442\n","\n","Epoch 00025: val_loss improved from 0.40367 to 0.40179, saving model to keras_model1.model\n","Epoch 26/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.2112 - acc: 0.0248 - val_loss: 0.3994 - val_acc: 0.0458\n","\n","Epoch 00026: val_loss improved from 0.40179 to 0.39942, saving model to keras_model1.model\n","Epoch 27/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2074 - acc: 0.0252 - val_loss: 0.3968 - val_acc: 0.0457\n","\n","Epoch 00027: val_loss improved from 0.39942 to 0.39684, saving model to keras_model1.model\n","Epoch 28/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.2050 - acc: 0.0254 - val_loss: 0.4060 - val_acc: 0.0453\n","\n","Epoch 00028: val_loss did not improve from 0.39684\n","Epoch 29/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.2015 - acc: 0.0261 - val_loss: 0.3914 - val_acc: 0.0475\n","\n","Epoch 00029: val_loss improved from 0.39684 to 0.39137, saving model to keras_model1.model\n","Epoch 30/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1999 - acc: 0.0263 - val_loss: 0.3918 - val_acc: 0.0466\n","\n","Epoch 00030: val_loss did not improve from 0.39137\n","Epoch 31/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1966 - acc: 0.0267 - val_loss: 0.3989 - val_acc: 0.0455\n","\n","Epoch 00031: val_loss did not improve from 0.39137\n","Epoch 32/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1942 - acc: 0.0273 - val_loss: 0.3899 - val_acc: 0.0477\n","\n","Epoch 00032: val_loss improved from 0.39137 to 0.38993, saving model to keras_model1.model\n","Epoch 33/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1926 - acc: 0.0271 - val_loss: 0.3933 - val_acc: 0.0473\n","\n","Epoch 00033: val_loss did not improve from 0.38993\n","Epoch 34/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1885 - acc: 0.0281 - val_loss: 0.3878 - val_acc: 0.0481\n","\n","Epoch 00034: val_loss improved from 0.38993 to 0.38784, saving model to keras_model1.model\n","Epoch 35/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1859 - acc: 0.0284 - val_loss: 0.3878 - val_acc: 0.0482\n","\n","Epoch 00035: val_loss improved from 0.38784 to 0.38778, saving model to keras_model1.model\n","Epoch 36/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1832 - acc: 0.0284 - val_loss: 0.3912 - val_acc: 0.0475\n","\n","Epoch 00036: val_loss did not improve from 0.38778\n","Epoch 37/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1821 - acc: 0.0286 - val_loss: 0.3884 - val_acc: 0.0476\n","\n","Epoch 00037: val_loss did not improve from 0.38778\n","Epoch 38/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1779 - acc: 0.0294 - val_loss: 0.3926 - val_acc: 0.0470\n","\n","Epoch 00038: val_loss did not improve from 0.38778\n","Epoch 39/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1775 - acc: 0.0294 - val_loss: 0.3865 - val_acc: 0.0488\n","\n","Epoch 00039: val_loss improved from 0.38778 to 0.38645, saving model to keras_model1.model\n","Epoch 40/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1749 - acc: 0.0297 - val_loss: 0.3879 - val_acc: 0.0487\n","\n","Epoch 00040: val_loss did not improve from 0.38645\n","Epoch 41/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1718 - acc: 0.0303 - val_loss: 0.3869 - val_acc: 0.0493\n","\n","Epoch 00041: val_loss did not improve from 0.38645\n","Epoch 42/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1716 - acc: 0.0300 - val_loss: 0.3849 - val_acc: 0.0495\n","\n","Epoch 00042: val_loss improved from 0.38645 to 0.38489, saving model to keras_model1.model\n","Epoch 43/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1666 - acc: 0.0307 - val_loss: 0.3851 - val_acc: 0.0501\n","\n","Epoch 00043: val_loss did not improve from 0.38489\n","Epoch 44/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1665 - acc: 0.0309 - val_loss: 0.3869 - val_acc: 0.0492\n","\n","Epoch 00044: val_loss did not improve from 0.38489\n","Epoch 45/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1632 - acc: 0.0314 - val_loss: 0.3879 - val_acc: 0.0486\n","\n","Epoch 00045: val_loss did not improve from 0.38489\n","Epoch 46/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1621 - acc: 0.0317 - val_loss: 0.3837 - val_acc: 0.0491\n","\n","Epoch 00046: val_loss improved from 0.38489 to 0.38370, saving model to keras_model1.model\n","Epoch 47/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1592 - acc: 0.0321 - val_loss: 0.3897 - val_acc: 0.0481\n","\n","Epoch 00047: val_loss did not improve from 0.38370\n","Epoch 48/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1580 - acc: 0.0321 - val_loss: 0.3858 - val_acc: 0.0487\n","\n","Epoch 00048: val_loss did not improve from 0.38370\n","Epoch 49/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1559 - acc: 0.0324 - val_loss: 0.3824 - val_acc: 0.0503\n","\n","Epoch 00049: val_loss improved from 0.38370 to 0.38238, saving model to keras_model1.model\n","Epoch 50/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1536 - acc: 0.0330 - val_loss: 0.3847 - val_acc: 0.0491\n","\n","Epoch 00050: val_loss did not improve from 0.38238\n","Epoch 51/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1515 - acc: 0.0332 - val_loss: 0.3865 - val_acc: 0.0502\n","\n","Epoch 00051: val_loss did not improve from 0.38238\n","Epoch 52/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1506 - acc: 0.0334 - val_loss: 0.3857 - val_acc: 0.0491\n","\n","Epoch 00052: val_loss did not improve from 0.38238\n","Epoch 53/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1469 - acc: 0.0339 - val_loss: 0.3810 - val_acc: 0.0503\n","\n","Epoch 00053: val_loss improved from 0.38238 to 0.38098, saving model to keras_model1.model\n","Epoch 54/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1457 - acc: 0.0340 - val_loss: 0.3881 - val_acc: 0.0494\n","\n","Epoch 00054: val_loss did not improve from 0.38098\n","Epoch 55/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1431 - acc: 0.0346 - val_loss: 0.3830 - val_acc: 0.0502\n","\n","Epoch 00055: val_loss did not improve from 0.38098\n","Epoch 56/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1418 - acc: 0.0348 - val_loss: 0.3845 - val_acc: 0.0505\n","\n","Epoch 00056: val_loss did not improve from 0.38098\n","Epoch 57/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1392 - acc: 0.0352 - val_loss: 0.3850 - val_acc: 0.0505\n","\n","Epoch 00057: val_loss did not improve from 0.38098\n","Epoch 58/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1383 - acc: 0.0351 - val_loss: 0.3856 - val_acc: 0.0501\n","\n","Epoch 00058: val_loss did not improve from 0.38098\n","Epoch 59/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1371 - acc: 0.0353 - val_loss: 0.3852 - val_acc: 0.0505\n","\n","Epoch 00059: val_loss did not improve from 0.38098\n","Epoch 60/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1348 - acc: 0.0361 - val_loss: 0.3874 - val_acc: 0.0506\n","\n","Epoch 00060: val_loss did not improve from 0.38098\n","Epoch 61/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1326 - acc: 0.0364 - val_loss: 0.3828 - val_acc: 0.0507\n","\n","Epoch 00061: val_loss did not improve from 0.38098\n","Epoch 62/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1309 - acc: 0.0362 - val_loss: 0.3865 - val_acc: 0.0509\n","\n","Epoch 00062: val_loss did not improve from 0.38098\n","Epoch 63/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1271 - acc: 0.0372 - val_loss: 0.3874 - val_acc: 0.0504\n","\n","Epoch 00063: val_loss did not improve from 0.38098\n","Epoch 64/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1289 - acc: 0.0368 - val_loss: 0.3872 - val_acc: 0.0510\n","\n","Epoch 00064: val_loss did not improve from 0.38098\n","Epoch 65/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1263 - acc: 0.0372 - val_loss: 0.3857 - val_acc: 0.0515\n","\n","Epoch 00065: val_loss did not improve from 0.38098\n","Epoch 66/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1239 - acc: 0.0379 - val_loss: 0.3847 - val_acc: 0.0519\n","\n","Epoch 00066: val_loss did not improve from 0.38098\n","Epoch 67/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1230 - acc: 0.0376 - val_loss: 0.3929 - val_acc: 0.0496\n","\n","Epoch 00067: val_loss did not improve from 0.38098\n","Epoch 68/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1211 - acc: 0.0382 - val_loss: 0.3911 - val_acc: 0.0512\n","\n","Epoch 00068: val_loss did not improve from 0.38098\n","Epoch 69/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1203 - acc: 0.0384 - val_loss: 0.3923 - val_acc: 0.0510\n","\n","Epoch 00069: val_loss did not improve from 0.38098\n","Epoch 70/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1199 - acc: 0.0382 - val_loss: 0.3841 - val_acc: 0.0518\n","\n","Epoch 00070: val_loss did not improve from 0.38098\n","Epoch 71/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1160 - acc: 0.0393 - val_loss: 0.3831 - val_acc: 0.0524\n","\n","Epoch 00071: val_loss did not improve from 0.38098\n","Epoch 72/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1157 - acc: 0.0393 - val_loss: 0.3867 - val_acc: 0.0516\n","\n","Epoch 00072: val_loss did not improve from 0.38098\n","Epoch 73/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1130 - acc: 0.0398 - val_loss: 0.3911 - val_acc: 0.0506\n","\n","Epoch 00073: val_loss did not improve from 0.38098\n","Epoch 74/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1126 - acc: 0.0399 - val_loss: 0.3875 - val_acc: 0.0525\n","\n","Epoch 00074: val_loss did not improve from 0.38098\n","Epoch 75/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.1125 - acc: 0.0396 - val_loss: 0.3911 - val_acc: 0.0513\n","\n","Epoch 00075: val_loss did not improve from 0.38098\n","Epoch 76/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1080 - acc: 0.0405 - val_loss: 0.3909 - val_acc: 0.0515\n","\n","Epoch 00076: val_loss did not improve from 0.38098\n","Epoch 77/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1070 - acc: 0.0411 - val_loss: 0.3950 - val_acc: 0.0517\n","\n","Epoch 00077: val_loss did not improve from 0.38098\n","Epoch 78/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1056 - acc: 0.0415 - val_loss: 0.3958 - val_acc: 0.0523\n","\n","Epoch 00078: val_loss did not improve from 0.38098\n","Epoch 79/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1034 - acc: 0.0414 - val_loss: 0.3970 - val_acc: 0.0504\n","\n","Epoch 00079: val_loss did not improve from 0.38098\n","Epoch 80/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.1041 - acc: 0.0414 - val_loss: 0.3907 - val_acc: 0.0525\n","\n","Epoch 00080: val_loss did not improve from 0.38098\n","Epoch 81/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1034 - acc: 0.0415 - val_loss: 0.3950 - val_acc: 0.0513\n","\n","Epoch 00081: val_loss did not improve from 0.38098\n","Epoch 82/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.1018 - acc: 0.0420 - val_loss: 0.3906 - val_acc: 0.0527\n","\n","Epoch 00082: val_loss did not improve from 0.38098\n","Epoch 83/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0993 - acc: 0.0426 - val_loss: 0.3957 - val_acc: 0.0520\n","\n","Epoch 00083: val_loss did not improve from 0.38098\n","Epoch 84/100\n","939/939 [==============================] - 14s 14ms/step - loss: 0.0976 - acc: 0.0429 - val_loss: 0.3986 - val_acc: 0.0519\n","\n","Epoch 00084: val_loss did not improve from 0.38098\n","Epoch 85/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0991 - acc: 0.0422 - val_loss: 0.3975 - val_acc: 0.0519\n","\n","Epoch 00085: val_loss did not improve from 0.38098\n","Epoch 86/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0955 - acc: 0.0431 - val_loss: 0.3998 - val_acc: 0.0519\n","\n","Epoch 00086: val_loss did not improve from 0.38098\n","Epoch 87/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0967 - acc: 0.0426 - val_loss: 0.3952 - val_acc: 0.0523\n","\n","Epoch 00087: val_loss did not improve from 0.38098\n","Epoch 88/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0928 - acc: 0.0442 - val_loss: 0.3944 - val_acc: 0.0523\n","\n","Epoch 00088: val_loss did not improve from 0.38098\n","Epoch 89/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0924 - acc: 0.0440 - val_loss: 0.3983 - val_acc: 0.0520\n","\n","Epoch 00089: val_loss did not improve from 0.38098\n","Epoch 90/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0930 - acc: 0.0435 - val_loss: 0.3964 - val_acc: 0.0524\n","\n","Epoch 00090: val_loss did not improve from 0.38098\n","Epoch 91/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0896 - acc: 0.0444 - val_loss: 0.3930 - val_acc: 0.0531\n","\n","Epoch 00091: val_loss did not improve from 0.38098\n","Epoch 92/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0871 - acc: 0.0452 - val_loss: 0.3954 - val_acc: 0.0529\n","\n","Epoch 00092: val_loss did not improve from 0.38098\n","Epoch 93/100\n","939/939 [==============================] - 14s 15ms/step - loss: 0.0881 - acc: 0.0448 - val_loss: 0.3992 - val_acc: 0.0519\n","\n","Epoch 00093: val_loss did not improve from 0.38098\n","Epoch 94/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0859 - acc: 0.0452 - val_loss: 0.4033 - val_acc: 0.0518\n","\n","Epoch 00094: val_loss did not improve from 0.38098\n","Epoch 95/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0836 - acc: 0.0461 - val_loss: 0.3990 - val_acc: 0.0522\n","\n","Epoch 00095: val_loss did not improve from 0.38098\n","Epoch 96/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0845 - acc: 0.0454 - val_loss: 0.4043 - val_acc: 0.0529\n","\n","Epoch 00096: val_loss did not improve from 0.38098\n","Epoch 97/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0832 - acc: 0.0455 - val_loss: 0.4005 - val_acc: 0.0528\n","\n","Epoch 00097: val_loss did not improve from 0.38098\n","Epoch 98/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0808 - acc: 0.0464 - val_loss: 0.3991 - val_acc: 0.0533\n","\n","Epoch 00098: val_loss did not improve from 0.38098\n","Epoch 99/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0779 - acc: 0.0468 - val_loss: 0.4007 - val_acc: 0.0531\n","\n","Epoch 00099: val_loss did not improve from 0.38098\n","Epoch 100/100\n","939/939 [==============================] - 13s 14ms/step - loss: 0.0773 - acc: 0.0473 - val_loss: 0.4057 - val_acc: 0.0528\n","\n","Epoch 00100: val_loss did not improve from 0.38098\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"PjndJjFddGrn","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":557},"outputId":"c21829a2-4e98-48a8-ed0f-6c9085561cff","executionInfo":{"status":"ok","timestamp":1582019765044,"user_tz":-540,"elapsed":5432,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["# 샘플링 모델 정의\n","encoder_model = models.Model(encoder_inputs, [encoder_outputs, state_h])\n","encoder_outputs_input = layers.Input(shape=(max_encoder_seq_length, latent_dim))\n","\n","decoder_inputs = layers.Input(shape=(1, num_decoder_tokens))\n","decoder_state_input_h = layers.Input(shape=(latent_dim,))\n","decoder_outputs, decoder_h = decoder(decoder_inputs, initial_state=decoder_state_input_h)\n","\n","repeat_d_layer = RepeatVectorLayer(max_encoder_seq_length, 2)\n","repeat_d = repeat_d_layer(decoder_outputs)\n","\n","repeat_e_layer = RepeatVectorLayer(1, axis=1)\n","repeat_e = repeat_e_layer(encoder_outputs_input)\n","\n","concat_for_score_layer = layers.Concatenate(axis=-1)\n","concat_for_score = concat_for_score_layer([repeat_d, repeat_e])\n","\n","dense1_score_layer = layers.TimeDistributed(dense1_t_score_layer)\n","dense1_score = dense1_score_layer(concat_for_score)\n","\n","dense2_score_layer = layers.TimeDistributed(dense2_t_score_layer)\n","dense2_score = dense2_score_layer(dense1_score)\n","dense2_score = layers.Reshape((1, max_encoder_seq_length))(dense2_score)\n","\n","softmax_score_layer = layers.Softmax(axis=-1)\n","softmax_score = softmax_score_layer(dense2_score)\n","\n","repeat_score_layer = RepeatVectorLayer(latent_dim, 2)\n","repeat_score = repeat_score_layer(softmax_score)\n","\n","permute_e = layers.Permute((2, 1))(encoder_outputs_input)\n","repeat_e_layer = RepeatVectorLayer(1, axis=1)\n","repeat_e = repeat_e_layer(permute_e)\n","\n","attended_mat_layer = layers.Multiply()\n","attended_mat = attended_mat_layer([repeat_score, repeat_e])\n","\n","context_layer = layers.Lambda(lambda x: K.sum(x, axis=-1),\n","                             lambda x: tuple(x[:-1]))\n","context = context_layer(attended_mat)\n","\n","concat_context_layer = layers.Concatenate(axis=-1)\n","concat_context = concat_context_layer([context, decoder_outputs])\n","\n","attention_output_layer = layers.TimeDistributed(attention_dense_output_layer)\n","attention_output = attention_output_layer(concat_context)\n","\n","decoder_att_outputs = decoder_dense(attention_output)\n","\n","decoder_model = models.Model([decoder_inputs, decoder_state_input_h, encoder_outputs_input],\n","                            [decoder_outputs, decoder_h, decoder_att_outputs])\n","\n","\n","def decode_sequence(input_seq):\n","  # 입력 문장을 인코딩\n","  enc_outputs, states_value = encoder_model.predict(input_seq)\n"," \n","  # 디코더의 입력으로 쓸 단일 문자\n","  target_seq = np.zeros((1, 1, num_decoder_tokens))\n","  # 첫 입력은 시작 문자인 '\\t'로 설정\n","  target_seq[0, 0, target_token_index['\\t']] = 1.\n"," \n","  # 문장 생성\n","  stop_condition = False\n","  decoded_sentence = ''\n","  while not stop_condition:\n","    # 이전의 출력, 상태를 디코더에 넣어서 새로운 출력, 상태를 얻음\n","    # 이전 문자와 상태로 다음 문자와 상태를 얻는다고 보면 됨.\n","    dec_outputs, h, output_tokens = decoder_model.predict(\n","        [target_seq, states_value, enc_outputs])\n"," \n","    # 사전을 사용해서 원 핫 인코딩 출력을 실제 문자로 변환\n","    sampled_token_index = np.argmax(output_tokens[0, -1, :])\n","    sampled_char = reverse_target_char_index[sampled_token_index]\n","    decoded_sentence += sampled_char\n"," \n","    # 종료 문자가 나왔거나 문장 길이가 한계를 넘으면 종료\n","    if (sampled_char == '\\n' or len(decoded_sentence) > max_decoder_seq_length):\n","      stop_condition = True\n"," \n","    # 디코더의 다음 입력으로 쓸 데이터 갱신\n","    target_seq = np.zeros((1, 1, num_decoder_tokens))\n","    target_seq[0, 0, sampled_token_index] = 1.\n","    \n","    states_value = h\n"," \n","  return decoded_sentence\n","\n","for seq_index in range(30):\n","  input_seq = encoder_input_data[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","  print('\"{}\" -> \"{}\"'.format(input_texts[seq_index], decoded_sentence.strip()))"],"execution_count":20,"outputs":[{"output_type":"stream","text":["\"버래기\" -> \"병아리\"\n","\"강생이\" -> \"강아지\"\n","\"부각허다\" -> \"부글부글하다\"\n","\"강알\" -> \"수\"\n","\"부끄다\" -> \"부끄럽다\"\n","\"개끔\" -> \"바다\"\n","\"분시몰랑\" -> \"고르다\"\n","\"개작개작\" -> \"부부가 하다\"\n","\"삐암데기\" -> \"잠\"\n","\"검질\" -> \"찹쌀\"\n","\"속슴허라\" -> \"말하지 말하다\"\n","\"게미융허다\" -> \"희미하다\"\n","\"솜쫄르멍\" -> \"달\"\n","\"게작헌\" -> \"상갓닮은거\"\n","\"쉰달이\" -> \"산간\"\n","\"고라불켜\" -> \"고함지\"\n","\"심토맥이\" -> \"상복마\"\n","\"곡기다\" -> \"고기다\"\n","\"영\" -> \"감물들인옷\"\n","\"골다\" -> \"다리다\"\n","\"왁왁허다\" -> \"캄캄하다\"\n","\"곱지다\" -> \"숨기다\"\n","\"요망지다\" -> \"똑똑하다\"\n","\"과랑과랑\" -> \"쨍쨍하다\"\n","\"우영밭\" -> \"상복\"\n","\"괸당\" -> \"친\"\n","\"웃뜨리\" -> \"산간마\"\n","\"굽\" -> \"바다\"\n","\"재짝재짝\" -> \"걷는 모습\"\n","\"기시리다\" -> \"달리\"\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-ZsELfVvdG-2","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":513},"outputId":"6a28d438-5c6c-4500-960a-ff1cee99ce16","executionInfo":{"status":"ok","timestamp":1582020544879,"user_tz":-540,"elapsed":1400,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["  # 손실 그래프\n","  plt.plot(history.history['loss'], 'y', label='train loss')\n","  plt.plot(history.history['val_loss'], 'r', label='val loss')\n","  plt.legend(loc='upper left')\n","  plt.show()\n","\n","  # 정확도 그래프\n","  plt.plot(history.history['acc'], 'y', label='train acc')\n","  plt.plot(history.history['val_acc'], 'r', label='val acc')\n","  plt.legend(loc='upper left')\n","  plt.show()"],"execution_count":21,"outputs":[{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}},{"output_type":"display_data","data":{"image/png":"iVBORw0KGgoAAAANSUhEUgAAAXoAAAD4CAYAAADiry33AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"d89Iq6JaLqou","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"454ad5f4-3f9b-4ff3-f20d-7077c125190c","executionInfo":{"status":"ok","timestamp":1582021631856,"user_tz":-540,"elapsed":21791,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["result= []\n","for seq_index in range(1,200,1):\n","  \n","  input_seq = encoder_input_data[seq_index: seq_index + 1]\n","  decoded_sentence = decode_sequence(input_seq)\n","  print('\"{}\" -> \"{}\"'.format(input_texts[seq_index], decoded_sentence.strip()))\n","  result.append(decoded_sentence.strip())\n","\n","result"],"execution_count":22,"outputs":[{"output_type":"stream","text":["\"강생이\" -> \"강아지\"\n","\"부각허다\" -> \"부글부글하다\"\n","\"강알\" -> \"수\"\n","\"부끄다\" -> \"부끄럽다\"\n","\"개끔\" -> \"바다\"\n","\"분시몰랑\" -> \"고르다\"\n","\"개작개작\" -> \"부부가 하다\"\n","\"삐암데기\" -> \"잠\"\n","\"검질\" -> \"찹쌀\"\n","\"속슴허라\" -> \"말하지 말하다\"\n","\"게미융허다\" -> \"희미하다\"\n","\"솜쫄르멍\" -> \"달\"\n","\"게작헌\" -> \"상갓닮은거\"\n","\"쉰달이\" -> \"산간\"\n","\"고라불켜\" -> \"고함지\"\n","\"심토맥이\" -> \"상복마\"\n","\"곡기다\" -> \"고기다\"\n","\"영\" -> \"감물들인옷\"\n","\"골다\" -> \"다리다\"\n","\"왁왁허다\" -> \"캄캄하다\"\n","\"곱지다\" -> \"숨기다\"\n","\"요망지다\" -> \"똑똑하다\"\n","\"과랑과랑\" -> \"쨍쨍하다\"\n","\"우영밭\" -> \"상복\"\n","\"괸당\" -> \"친\"\n","\"웃뜨리\" -> \"산간마\"\n","\"굽\" -> \"바다\"\n","\"재짝재짝\" -> \"걷는 모습\"\n","\"기시리다\" -> \"달리\"\n","\"제라헌\" -> \"제주\"\n","\"꽝\" -> \"뼈\"\n","\"조그물다\" -> \"물물이다\"\n","\"촐래\" -> \"반찬\"\n","\"주레사니\" -> \"제주도 오르는 모습니다\"\n","\"니치름\" -> \"바람\"\n","\"촘아가라\" -> \"아무지 말해 보아\"\n","\"데껴불켜\" -> \"던져버리다\"\n","\"칭원허다\" -> \"원통하다\"\n","\"두렁청허다\" -> \"떨떨하다\"\n","\"콥데사니\" -> \"버리\"\n","\"들러켬쩌\" -> \"날뛰다\"\n","\"코시롱\" -> \"향기\"\n","\"허다\" -> \"다니다\"\n","\"듬삭하다\" -> \"푸짐하다\"\n","\"탈\" -> \"씨앗\"\n","\"멜라지켜\" -> \"그러지다\"\n","\"통시\" -> \"감물들인옷\"\n","\"메기독딱\" -> \"얼굴\"\n","\"트멍\" -> \"주머니\"\n","\"모소완\" -> \"사모\"\n","\"하근디\" -> \"늑장부리다\"\n","\"몬뜨글락\" -> \"홀랑벗은모습\"\n","\"하다\" -> \"다니다\"\n","\"몬직당\" -> \"바다\"\n","\"몬짝\" -> \"감물들인옷\"\n","\"허당말타\" -> \"안하다\"\n","\"몰명허다\" -> \"개미하다\"\n","\"헌저글라\" -> \"그저께\"\n","\"몽케다\" -> \"까마리다\"\n","\"호썰\" -> \"조금\"\n","\"무리다\" -> \"무리다\"\n","\"호야\" -> \"시원하다\"\n","\"무사\" -> \"왜 그렇게 말입니다\"\n","\"흐랑허다\" -> \"부지런하다\"\n","\"배롱허다\" -> \"희미하다\"\n","\"허운데기\" -> \"미끄러지\"\n","\"배지금허다\" -> \"소리지\"\n","\"쪼광\" -> \"모습\"\n","\"물옷\" -> \"물속옷\"\n","\"센 바당\" -> \"바다\"\n","\"앞바르\" -> \"바가지\"\n","\"난바르\" -> \"바다\"\n","\"산목 졸르면 비온다\" -> \"비가 날뛰는 산 날 쇠꼬리\"\n","\"돌 갓쓰민 우친다\" -> \"달무리 말하면 달려라\"\n","\"곰새기 들럭 켬져\" -> \"날 날뛴다\"\n","\"토끼썼다\" -> \"상복\"\n","\"큰눈\" -> \"눈이 캄캄\"\n","\"소살\" -> \"살\"\n","\"머정좋다\" -> \"산물을 많이 잡았다\"\n","\"제수가 좋다\" -> \"정말로 좋습니다\"\n","\"궐 면했다\" -> \"덴 곳에 털 안히다\"\n","\"마당 바랏져\" -> \"바다가 잔잔하다\"\n","\"큰누\" -> \"산이\"\n","\"작은누\" -> \"작은 있는 바람\"\n","\"절 치대긴다\" -> \"물속으로\"\n","\"하르방 \" -> \"버지\"\n","\"할망 \" -> \"버리지\"\n","\"아방 \" -> \"아버지\"\n","\"어멍 \" -> \"어머니\"\n","\"비바리 \" -> \"바다\"\n","\"괸당 \" -> \"바다\"\n","\"걸바시 \" -> \"바가지\"\n","\"넹바리 \" -> \"바다\"\n","\"다슴아돌 \" -> \"아침\"\n","\"말젯놈 \" -> \"남자\"\n","\"소나이 \" -> \"나무\"\n","\"성님 \" -> \"감물들인옷\"\n","\"작산 거 \" -> \"사람이\"\n","\"좀녀 \" -> \"해녀\"\n","\"촐람생이 \" -> \"경솔한사람\"\n","\"홀아방 \" -> \"아버지\"\n","\"가달 \" -> \"다\"\n","\"꼴랑지 \" -> \"무리\"\n","\"구뚱배기 \" -> \"닭\"\n","\"꽝 \" -> \"뼈\"\n","\"굴레 \" -> \"상복\"\n","\"대망생이 \" -> \"배\"\n","\"등땡이 \" -> \"등어리\"\n","\"또꼬망 \" -> \"개구리\"\n","\"모감지 \" -> \"멱살\"\n","\"베 봉탱이 \" -> \"불뚝이\"\n","\"베아지 볼라불라\" -> \"아지\"\n","\"상판이 \" -> \"상투\"\n","\"야게기 \" -> \"머리\"\n","\"야굴탁 \" -> \"상갓닮은거\"\n","\"임댕이 \" -> \"이\"\n","\"정겡이 \" -> \"종아리\"\n","\"저껭이 \" -> \"고양이\"\n","\"조금태기 \" -> \"여자모자\"\n","\"좀짐팽이 \" -> \"종아리\"\n","\"허운데기 \" -> \"미끄러지\"\n","\"허벅다리 \" -> \"넓적다리\"\n","\"놋 \" -> \"얼굴\"\n","\"간수메 \" -> \"수복\"\n","\"개역 \" -> \"버리빗\"\n","\"것 \" -> \"감물들인옷\"\n","\"괴기 \" -> \"돼지\"\n","\"바당괴기 \" -> \"바다\"\n","\"돗괴기 \" -> \"돼지고기\"\n","\"쇠괴기 \" -> \"고기\"\n","\"도괴기 \" -> \"돼지고기\"\n","\"곤떡 \" -> \"쌀로만든하얀떡\"\n","\"곤밥 \" -> \"쌀로\"\n","\"놈삐 \" -> \"감물들인옷\"\n","\"대사니김치 \" -> \"마늘\"\n","\"마농 \" -> \"마늘\"\n","\"조배기 \" -> \"돼지\"\n","\"촐래 \" -> \"작은밭\"\n","\"촘지금 \" -> \"소\"\n","\"짐치 \" -> \"비온날\"\n","\"촙쏠 \" -> \"찹쌀\"\n","\"조팝 \" -> \"조마\"\n","\"갈옷 \" -> \"상갓닮은거\"\n","\"갈 중이 \" -> \"고쟁이\"\n","\"강알터진 바지 \" -> \"개구멍 바다\"\n","\"게와 \" -> \"씨앗\"\n","\"단취 \" -> \"다\"\n","\"밀랑 페랭이 \" -> \"밀짚 모자\"\n","\"보선 \" -> \"버선\"\n","\"소중이 \" -> \"상갓\"\n","\"신착 \" -> \"비신\"\n","\"찍신 \" -> \"감물들인옷\"\n","\"좀뱅이 \" -> \"잠잠\"\n","\"등지게 \" -> \"호미\"\n","\"고장중이 \" -> \"고양이\"\n","\"도폭 \" -> \"달\"\n","\"두루막 \" -> \"두루마기\"\n","\"베불레기 \" -> \"바가지\"\n","\"우장 \" -> \"비녀\"\n","\"저구리 \" -> \"무리\"\n","\"지성귀 \" -> \"귀소\"\n","\"지서귀 \" -> \"소리\"\n","\"쪼께 \" -> \"조금\"\n","\"치메 \" -> \"치마\"\n","\"건대 \" -> \"건대\"\n","\"사모관대 \" -> \"사모관대\"\n","\"시미옷 \" -> \"상복\"\n","\"제복 \" -> \"상복\"\n","\"망근 \" -> \"감물들인옷\"\n","\"방립 \" -> \"상갓닮은거\"\n","\"벙것 \" -> \"감물들인옷\"\n","\"상갓 \" -> \"무리\"\n","\"탕근 \" -> \"탕건\"\n","\"풍뎅이 \" -> \"남자모자\"\n","\"휘양 \" -> \"여자모자\"\n","\"낭저 \" -> \"그저께\"\n","\"달리 \" -> \"돼지\"\n","\"빈네 \" -> \"비녀\"\n","\"상퉁이 \" -> \"상투\"\n","\"얼레기 \" -> \"물속으로\"\n","\"얼레빗 \" -> \"머리빗\"\n","\"쪽도리 \" -> \"돼지\"\n","\"쳉빗 \" -> \"참빗\"\n","\"과지 \" -> \"여자모자\"\n","\"남신 \" -> \"화장실\"\n","\"송락 \" -> \"감물들인옷\"\n","\"요령 \" -> \"작은 모르는 모습\"\n","\"복치메 \" -> \"상복치마\"\n","\"구덕 \" -> \"바구니\"\n","\"고량착 \" -> \"조끼\"\n","\"낭푼이 \" -> \"양푼\"\n","\"그릇대배기 \" -> \"물긷는그릇\"\n","\"물구루마 \" -> \"마마\"\n","\"바농 \" -> \"바늘\"\n","\"박새기 \" -> \"바가지\"\n","\"숟구락 \" -> \"무리\"\n","\"제끄락 \" -> \"바가지\"\n","\"주멩기 \" -> \"주머니\"\n","\"허벅 \" -> \"개미\"\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["['강아지',\n"," '부글부글하다',\n"," '수',\n"," '부끄럽다',\n"," '바다',\n"," '고르다',\n"," '부부가 하다',\n"," '잠',\n"," '찹쌀',\n"," '말하지 말하다',\n"," '희미하다',\n"," '달',\n"," '상갓닮은거',\n"," '산간',\n"," '고함지',\n"," '상복마',\n"," '고기다',\n"," '감물들인옷',\n"," '다리다',\n"," '캄캄하다',\n"," '숨기다',\n"," '똑똑하다',\n"," '쨍쨍하다',\n"," '상복',\n"," '친',\n"," '산간마',\n"," '바다',\n"," '걷는 모습',\n"," '달리',\n"," '제주',\n"," '뼈',\n"," '물물이다',\n"," '반찬',\n"," '제주도 오르는 모습니다',\n"," '바람',\n"," '아무지 말해 보아',\n"," '던져버리다',\n"," '원통하다',\n"," '떨떨하다',\n"," '버리',\n"," '날뛰다',\n"," '향기',\n"," '다니다',\n"," '푸짐하다',\n"," '씨앗',\n"," '그러지다',\n"," '감물들인옷',\n"," '얼굴',\n"," '주머니',\n"," '사모',\n"," '늑장부리다',\n"," '홀랑벗은모습',\n"," '다니다',\n"," '바다',\n"," '감물들인옷',\n"," '안하다',\n"," '개미하다',\n"," '그저께',\n"," '까마리다',\n"," '조금',\n"," '무리다',\n"," '시원하다',\n"," '왜 그렇게 말입니다',\n"," '부지런하다',\n"," '희미하다',\n"," '미끄러지',\n"," '소리지',\n"," '모습',\n"," '물속옷',\n"," '바다',\n"," '바가지',\n"," '바다',\n"," '비가 날뛰는 산 날 쇠꼬리',\n"," '달무리 말하면 달려라',\n"," '날 날뛴다',\n"," '상복',\n"," '눈이 캄캄',\n"," '살',\n"," '산물을 많이 잡았다',\n"," '정말로 좋습니다',\n"," '덴 곳에 털 안히다',\n"," '바다가 잔잔하다',\n"," '산이',\n"," '작은 있는 바람',\n"," '물속으로',\n"," '버지',\n"," '버리지',\n"," '아버지',\n"," '어머니',\n"," '바다',\n"," '바다',\n"," '바가지',\n"," '바다',\n"," '아침',\n"," '남자',\n"," '나무',\n"," '감물들인옷',\n"," '사람이',\n"," '해녀',\n"," '경솔한사람',\n"," '아버지',\n"," '다',\n"," '무리',\n"," '닭',\n"," '뼈',\n"," '상복',\n"," '배',\n"," '등어리',\n"," '개구리',\n"," '멱살',\n"," '불뚝이',\n"," '아지',\n"," '상투',\n"," '머리',\n"," '상갓닮은거',\n"," '이',\n"," '종아리',\n"," '고양이',\n"," '여자모자',\n"," '종아리',\n"," '미끄러지',\n"," '넓적다리',\n"," '얼굴',\n"," '수복',\n"," '버리빗',\n"," '감물들인옷',\n"," '돼지',\n"," '바다',\n"," '돼지고기',\n"," '고기',\n"," '돼지고기',\n"," '쌀로만든하얀떡',\n"," '쌀로',\n"," '감물들인옷',\n"," '마늘',\n"," '마늘',\n"," '돼지',\n"," '작은밭',\n"," '소',\n"," '비온날',\n"," '찹쌀',\n"," '조마',\n"," '상갓닮은거',\n"," '고쟁이',\n"," '개구멍 바다',\n"," '씨앗',\n"," '다',\n"," '밀짚 모자',\n"," '버선',\n"," '상갓',\n"," '비신',\n"," '감물들인옷',\n"," '잠잠',\n"," '호미',\n"," '고양이',\n"," '달',\n"," '두루마기',\n"," '바가지',\n"," '비녀',\n"," '무리',\n"," '귀소',\n"," '소리',\n"," '조금',\n"," '치마',\n"," '건대',\n"," '사모관대',\n"," '상복',\n"," '상복',\n"," '감물들인옷',\n"," '상갓닮은거',\n"," '감물들인옷',\n"," '무리',\n"," '탕건',\n"," '남자모자',\n"," '여자모자',\n"," '그저께',\n"," '돼지',\n"," '비녀',\n"," '상투',\n"," '물속으로',\n"," '머리빗',\n"," '돼지',\n"," '참빗',\n"," '여자모자',\n"," '화장실',\n"," '감물들인옷',\n"," '작은 모르는 모습',\n"," '상복치마',\n"," '바구니',\n"," '조끼',\n"," '양푼',\n"," '물긷는그릇',\n"," '마마',\n"," '바늘',\n"," '바가지',\n"," '무리',\n"," '바가지',\n"," '주머니',\n"," '개미']"]},"metadata":{"tags":[]},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"T8BHGWgn0dAy","colab_type":"text"},"source":["# 모델 검증"]},{"cell_type":"code","metadata":{"id":"k1q4xziu0gwX","colab_type":"code","colab":{}},"source":["target_texts2 = []\n","\n","with open(data_path, 'r', encoding='utf-8') as f:\n","    lines = f.read().split('\\n')\n","\n","for line in lines[: min(num_samples, len(lines) - 1)]:\n","    _, target_text2 = line.split('\\t')\n","    target_text2 = target_text2\n","    target_texts2.append(target_text2)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3Tt4hBhw14ot","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"f5aa6742-feac-4bb2-bb41-965f674831aa","executionInfo":{"status":"ok","timestamp":1582021715421,"user_tz":-540,"elapsed":1042,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["tar = target_texts2[1:200]\n","tar"],"execution_count":24,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['강아지',\n"," '부글부글하다',\n"," '가랭이',\n"," '부풀어 오르다',\n"," '거품',\n"," '정황도 모르고',\n"," '밥을 추하게 먹는 모습',\n"," '뺨',\n"," '잡초',\n"," '말하지말라',\n"," '희미하다',\n"," '숨막히는',\n"," '입이 큰',\n"," '유산식품',\n"," '고자질한다',\n"," '마음 씀씀이',\n"," '숨막히다',\n"," '이렇게',\n"," '잘게부수다',\n"," '캄캄하다',\n"," '숨기다',\n"," '똑똑하다',\n"," '햇살이 눈부시게 비추는모습',\n"," '텃밭',\n"," '친족',\n"," '산간마을',\n"," '밑바닥',\n"," '걷는 모습',\n"," '그을리다',\n"," '제대로 된',\n"," '뼈',\n"," '다물다',\n"," '반찬',\n"," '보리피리',\n"," '침',\n"," '어이없다',\n"," '던져버린다',\n"," '원통하다',\n"," '얼떨떨하다',\n"," '마늘',\n"," '날뛰다',\n"," '향기',\n"," '하다',\n"," '푸짐하다',\n"," '딸기',\n"," '찌그러지다',\n"," '돼지우리가 있는 변소',\n"," '아무것도 없음',\n"," '틈새',\n"," '무서워',\n"," '이곳저곳',\n"," '홀랑벗은모습',\n"," '많다',\n"," '만지다가',\n"," '전부',\n"," '하다가 안 할 것이냐',\n"," '멍청하다',\n"," '빨리가자',\n"," '늦장부리다',\n"," '조금',\n"," '맛이가다',\n"," '등',\n"," '왜?',\n"," '늘어지다',\n"," '어둠속에 빛이 희미하다',\n"," '얼굴',\n"," '고소하다',\n"," '모습',\n"," '잠수복',\n"," '거칠고 노한 바다',\n"," '가까운 바다',\n"," '먼 바다',\n"," '한라산의 중턱에 띠같은 구름이 끼면 비가 온다',\n"," '달무리지면 비가 온다',\n"," '돌고래가 날뛴다',\n"," '황사현상',\n"," '물안경',\n"," '작살',\n"," '해산물을 많이 잡았다',\n"," '해산물을 많이 잡았다',\n"," '겨우 한두개 잡았다',\n"," '바다가 잔잔하다',\n"," '산더미 같은 파도',\n"," '작은 파도',\n"," '물결이 친다',\n"," ' 할아버지',\n"," ' 할머니',\n"," '아버지',\n"," ' 어머니',\n"," ' 처녀',\n"," ' 친척',\n"," ' 거지',\n"," ' 색시',\n"," ' 의붓아들',\n"," ' 세번째자식',\n"," ' 사나이',\n"," ' 형님',\n"," ' 어른이된 사람',\n"," ' 해녀',\n"," ' 경솔한사람',\n"," ' 홀아비 ',\n"," ' 다리',\n"," ' 꼬리',\n"," ' 귀쪽뺨',\n"," ' 뼈',\n"," ' 입',\n"," ' 머리',\n"," ' 등어리',\n"," ' 똥구멍',\n"," ' 멱살',\n"," ' 배 불뚝이',\n"," ' 배 밟아버린다',\n"," ' 얼굴',\n"," ' 목',\n"," ' 턱',\n"," ' 이마',\n"," ' 종아리',\n"," ' 겨드랑이',\n"," '간지롭게',\n"," ' 종아리',\n"," '머리카락',\n"," ' 넓적다리',\n"," ' 얼굴',\n"," ' 통조림',\n"," ' 미숫가루',\n"," ' 동물먹이',\n"," ' 고기',\n"," ' 바닷고기',\n"," ' 돼지고기',\n"," ' 쇠고기',\n"," ' 돼지고기',\n"," ' 쌀로만든하얀떡',\n"," ' 흰쌀밥',\n"," ' 무우',\n"," ' 마늘장아찌',\n"," ' 마늘',\n"," ' 메밀수제비',\n"," ' 반찬',\n"," ' 참기름',\n"," ' 김치',\n"," ' 찹쌀',\n"," ' 조밥',\n"," ' 감물들인옷',\n"," ' 감물들인 고의',\n"," ' 개구멍 바지',\n"," ' 호주머니',\n"," ' 단추',\n"," ' 밀짚 모자',\n"," ' 버선',\n"," ' 속옷',\n"," ' 신짝',\n"," ' 짚신',\n"," ' 잠방이',\n"," ' 감물들인베옷',\n"," ' 고쟁이',\n"," ' 우두머니',\n"," ' 두루마기',\n"," ' 아기옷',\n"," ' 비온날',\n"," ' 저고리 ',\n"," ' 기저귀',\n"," ' 기저귀',\n"," ' 조끼',\n"," ' 치마',\n"," ' 건대',\n"," ' 사모관대',\n"," ' 손자용상복',\n"," ' 상제옷',\n"," ' 망건',\n"," ' 상갓닮은거',\n"," ' 벙거지',\n"," ' 삿갓',\n"," ' 탕건',\n"," ' 남자모자',\n"," ' 여자모자',\n"," ' 빈네꽂은머리',\n"," ' 땋은놈의머리',\n"," ' 비녀',\n"," ' 상투',\n"," ' 머리빗',\n"," ' 머리빗',\n"," ' 족두리',\n"," ' 참빗',\n"," ' 무당입는옷',\n"," ' 나막신',\n"," ' 무당들 쓰는 모자',\n"," ' 방울',\n"," ' 상복치마',\n"," ' 바구니',\n"," ' 대로만든채롱',\n"," ' 양푼',\n"," ' 물긷는그릇',\n"," ' 마차',\n"," ' 바늘',\n"," ' 바가지',\n"," ' 수저',\n"," ' 젓갈',\n"," ' 주머니',\n"," ' 물을길어나르는통']"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"Eh61iGcW2USA","colab_type":"text"},"source":["# 평가 BLEU\n","\n","\n","\n","### 바이그램(Bigram) 단위로 카운트하여 Example 1, 2의 바이그램 정밀도(Bigram Precision)를 계산, 3gram, 4gram,,,ngram까지 정밀도 계산한다\n","![대체 텍스트](https://img1.daumcdn.net/thumb/R720x0.q80/?scode=mtistory2&fname=http%3A%2F%2Fcfile2.uf.tistory.com%2Fimage%2F99B791335C67C9FE250064)\n","---\n","\n","BLEU는 보정된 정밀도 p1,p2,...,pn를 모두 조합하여 사용합니다.\n"," (pn 에서 n은 n-gram에서의 n을 의미)\n","\n","![대체 텍스트](https://sjiang1.github.io/talks/ASE2017/11.PNG)\n","\n","https://wikidocs.net/31695"]},{"cell_type":"markdown","metadata":{"id":"H4Tr7tXg2pG4","colab_type":"text"},"source":["# 5) 짧은 문장 길이에 대한 패널티(Brevity Penalty)\n","\n","문장의 길이가 짧다는 이유로 분모가 작기 때문에 높은 점수를 받는 것은 이상합니다. 그래서 Ca가 Ref보다 문장의 길이가 짧은 경우에는 점수에 패널티를 줄 필요가 있습니다. 이를 브레버티 패널티(Brevity Penalty)라고 합니다.\n","\n","위의 수식은 패널티를 줄 필요가 없는 경우에는 BP의 값이 1이어야 함을 의미합니다. 이를 반영한 BP의 수식은 아래와 같습니다.\n","\n","    BP = { 1          if c>r\n","         { e(1−r/c)   if c≤r\n","\n","          c : Candidate의 길이\n","          r : Candidate와 가장 길이 차이가 작은 Reference의 길이"]},{"cell_type":"code","metadata":{"id":"b5iSDLxD16Fs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":179},"outputId":"384b104c-1055-4375-9cca-ec52676373db","executionInfo":{"status":"ok","timestamp":1582021727161,"user_tz":-540,"elapsed":1586,"user":{"displayName":"송지나","photoUrl":"","userId":"11178834628279806640"}}},"source":["def dap(result, tar):\n","  import nltk.translate.bleu_score as bleu\n","  candidate = []\n","  references = []\n","  dap = []\n","  for i in range(0,len(result),1):\n","    re = []\n","    candidate = result[i]\n","    re.append(tar[i])\n","    dap.append(bleu.sentence_bleu(list(map(lambda ref: ref.split(), re)),candidate.split()))\n","  return sum(dap)/len(result)\n","# 성능테스트\n","dap(result,tar)"],"execution_count":25,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 2-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n","/usr/local/lib/python3.6/dist-packages/nltk/translate/bleu_score.py:490: UserWarning: \n","Corpus/Sentence contains 0 counts of 3-gram overlaps.\n","BLEU scores might be undesirable; use SmoothingFunction().\n","  warnings.warn(_msg)\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["0.2947545913700724"]},"metadata":{"tags":[]},"execution_count":25}]},{"cell_type":"code","metadata":{"id":"J7Qq-KPK2GXk","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nBbiMKL13m0H","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}