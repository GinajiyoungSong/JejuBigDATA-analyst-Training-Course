{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "머신러닝( 기계학습 )\n",
    "-지도학습(supervised learning): 입력에 대한 종속변수가 있음: 대조해 학습\n",
    "        -backpropagation\n",
    "-비지도학습(unsupervised learning) : 독립변수 입력만 주어짐\n",
    "        -clustering, autoencoder\n",
    "        \n",
    "-강화학습(reinforcement learing): 독립변수에 대한 평, 보상을 줌 - 보상받기위해 학습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "머신러닝 - 유사도 및 군집화 방법 (Similarity&Clustering)KMeans, KNN\n",
    "https://www.slideshare.net/TaeYoungLee1/20141214-similarityclustering\n",
    "    \n",
    "    1)유사도매칭 - 알려진 데이토에 기반해 비슷한 개체를 찾아냄\n",
    "    유사도 매칭은 고객에게 제품을 추천할 때 사용하는 가장 인기있는 방법 중 하나\n",
    "    선호하거나 구매한 제품의 관점에서 현재 고객과 유사한 사람을 찾아낼 수 있음\n",
    "    분츄,회귀 분석, 군집화와 같은 여러 데이터 마이닝 작업을 해결하기 위한 기반\n",
    "    - ex,Euclidean distance(유클라디안거리)\n",
    "       \n",
    "\n",
    "@KNN(k-nearest neighbor) 알고리즘 : 가장 가까운 k개의 객체들 중 가장 많은 특징으로 판단\n",
    " - 유사도 반영 w():x와y간의 유사도 기반 가중치함수 : 유클라디안 거리 제곱의 역수\n",
    " - 기여도 반영\n",
    "    \n",
    "\n",
    "    \n",
    "    2)군집화\n",
    "    특정목적이 없는 상태에서 유사도에 따라 개체를 묶는다\n",
    "    군집화는 문제 영역의 기초조사를 수행할떄 어떤 그룹이 자연스럽게 만들어지는지 \n",
    "    그룹이 존재한다면 다른 데이터마이닝 작업을 해볼 필요가 있다는 의미\n",
    "    \n",
    "@K-Means 알고리즘 : k는 데이터들 중에서 찾아내려는 군집의 수\n",
    "    1.k개의 임의위치에 클러스터 중심 할당\n",
    "    2.k개의 클러스터 중심이 바뀌지 않을떄까지 반복:\n",
    "        -모든객체들은 k개 클러스터 중심과 거리계산\n",
    "        -계산된 객체는 가장 가까운 k클러스터로 포함됨\n",
    "        -각각의 k클러스터에 포함된 클러스터 중심을 재계산\n",
    "        \n",
    "        -새로운 객체는 가장 가까운 중심점을 가진 클러스터 k로 분류\n",
    "        -새로운 객체를 포함된 클러스터의 중심은 변경되므로 재계산하면 끝\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "1.KNN, K-Means의 단점\n",
    "- in memory-based 알고리즘 ???\n",
    "- 모든 객체들 간 거리계산으로 인한 부하발생\n",
    "- 빅데이터 처리에 불리\n",
    "\n",
    "2.K-Meams 단점\n",
    "k-Means는 초기 중심점 설정이 최종분류에 큰 영향을 끼침\n",
    "평균값 계산시 이상치(outlier)데이터가 미치는 영향이 크다.\n",
    "클러스터링 단위로 거리값을 이용하여 군집 형태가 '원'형태로 \n",
    "원에 속하지 못하는\n",
    "데이터는 외면받음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "머신러닝 하는데 있어\n",
    "Overfitting 데이터의 과대적합\n",
    "1) 문제는 간단한데 모델이 너무 복잡할때\n",
    "2) 주어진 데이터는 별로 없는데 모델이 복잡...\n",
    "\n",
    "모델이 복잡할때는 dropout : 랜덤하게 뉴런을 끊음으로써, 모델을 단순하게 만든다\n",
    "    \n",
    "\n",
    "    \n",
    "Vanishing Gradient ?? 미분어쩌고 모르겠음..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "https://www.slideshare.net/yonghakim900/ss-60252533\n",
    "    \n",
    "    \n",
    "신경망모델 ( 1957년에 나옴 )\n",
    "활성함수,결과값 정규화를 위해 사용\n",
    "ex) 0 보다크면 1로 간주하고 0보다 같거나 작으면 0\n",
    "y=act(x0*w0_x1*w1 ~~~ xn*wn) # 내적 => 신경망 모델에는 벡터내적 연산\n",
    "\n",
    "x0= 상수 문턱값으로 -1고정\n",
    "w0-n 까지는 -0.5~0.5까지 랜덤초기화 => 입력값에 대해 적절한 출력값을 내도록 w 조정\n",
    "\n",
    "입력값을 넣었을 떄 출력값이 타겟값과 다르면 출력이 타겟값에 가까워질수 있도록\n",
    "가중치를 조정한다(학습률조정)\n",
    "\n",
    "단층 퍼셉트론 = \n",
    "퍼셉트론 구조 : 입련단에 가중치를 곱한것의 합이 \n",
    "    activation funtion의 역치를 넘기면 1을 그렇지않으면 -1을 넘겨주도록 모델링함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "https://www.slideshare.net/Byungwook/1-knn\n",
    "    핸즈온 머신러닝 = 용어비슷하니 참조"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
