{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corgi  파일 길이 :  970\n",
      "corgi  :  .//corgi\\corgi 10.jpg\n",
      "corgi  :  .//corgi\\corgi2909.jpg\n",
      "golden  파일 길이 :  799\n",
      "golden  :  .//golden\\gold (1).jpg\n",
      "golden  :  .//golden\\gold_dog665.jpg\n",
      "dach  파일 길이 :  945\n",
      "dach  :  .//dach\\dachs.jpg\n",
      "dach  :  .//dach\\docss (67).jpg\n",
      "husky  파일 길이 :  502\n",
      "husky  :  .//husky\\husky1.jpg\n",
      "beagle  파일 길이 :  803\n",
      "beagle  :  .//beagle\\beagle (1).jpg\n",
      "beagle  :  .//beagle\\beagle645.jpg\n",
      "ok 4019\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os, glob, numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "caltech_dir = \"./\"\n",
    "categories = [\"corgi\", \"golden\" ,\"dach\" ,\"husky\" ,\"beagle\"] # 각 카테고리 폴더에서 불러오기\n",
    "nb_classes = len(categories)\n",
    "\n",
    "image_w = 100\n",
    "image_h = 100\n",
    "\n",
    "pixels = image_h * image_w * 3\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "\n",
    "for idx, cat in enumerate(categories):\n",
    "    \n",
    "    #one-hot 돌리기.\n",
    "    label = [0 for i in range(nb_classes)]\n",
    "    label[idx] = 1\n",
    "\n",
    "    image_dir = caltech_dir + \"/\" + cat\n",
    "    files = glob.glob(image_dir+\"/*.jpg\")\n",
    "    print(cat, \" 파일 길이 : \", len(files))\n",
    "    for i, f in enumerate(files):\n",
    "        img = Image.open(f)\n",
    "        img = img.convert(\"RGB\")\n",
    "        img = img.resize((image_w, image_h))\n",
    "        data = np.asarray(img)\n",
    "\n",
    "        X.append(data)\n",
    "        y.append(label)\n",
    "\n",
    "        if i % 700 == 0:\n",
    "            print(cat, \" : \", f)\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "#1 0 0 0 이면 airplanes\n",
    "#0 1 0 0 이면 buddha 이런식\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "xy = (X_train, X_test, y_train, y_test)\n",
    "np.save(\"./multi_image_data.npy\", xy)\n",
    "\n",
    "print(\"ok\", len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3014, 100, 100, 3)\n",
      "3014\n",
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 11741685945767618669\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import os, glob, numpy as np\n",
    "import tensorflow.keras as keras\n",
    "# module 'tensorflow' has no attribute 'get_default_graph'\n",
    "from keras.models import Model, Input\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Dropout\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import keras.backend.tensorflow_backend as K\n",
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()\n",
    "import tensorflow as tf\n",
    "'''\n",
    "config = tf.ConfigProto()  텐서플로우 2. 에서 구동안됨\n",
    "module 'tensorflow' has no attribute 'ConfigProto'\n",
    "'''\n",
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "# session = tf.Session(config=config) 자동세션기능\n",
    "X_train, X_test, y_train, y_test = np.load('./multi_image_data.npy',allow_pickle=True)\n",
    "print(X_train.shape)\n",
    "print(X_train.shape[0])\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (3014, 100, 100, 3) | y_train shape: (3014, 5)\n",
      "X_test shape : (1005, 100, 100, 3) | y_test shape : (1005, 5)\n"
     ]
    }
   ],
   "source": [
    "categories = [\"corgi\", \"golden\" ,\"dach\" ,\"husky\" ,\"beagle\"]\n",
    "nb_classes = len(categories)\n",
    "\n",
    "#일반화\n",
    "X_train = X_train.astype(float) / 255\n",
    "X_test = X_test.astype(float) / 255\n",
    "\n",
    "print('X_train shape: {} | y_train shape: {}\\nX_test shape : {} | y_test shape : {}'.format(\n",
    "    X_train.shape, y_train.shape, X_test.shape, y_test.shape))\n",
    "\n",
    "\n",
    "#세개의 모델에서 같은 형태의 데이터를 사용할 것, 모든 모델에서 사용할 단일 입력 레이어를 정의.\n",
    "input_shape =X_train[0,:,:,:].shape\n",
    "model_input = Input(shape =input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"young_cnn\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 100, 100, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 100, 100, 32)      896       \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 100, 100, 32)      1056      \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 100, 100, 32)      1056      \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 100, 100, 32)      128       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 50, 50, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 50, 50, 64)        18496     \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 50, 50, 64)        4160      \n",
      "_________________________________________________________________\n",
      "conv2d_36 (Conv2D)           (None, 50, 50, 64)        4160      \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 50, 50, 64)        256       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 25, 25, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_37 (Conv2D)           (None, 25, 25, 128)       73856     \n",
      "_________________________________________________________________\n",
      "conv2d_38 (Conv2D)           (None, 25, 25, 256)       33024     \n",
      "_________________________________________________________________\n",
      "conv2d_39 (Conv2D)           (None, 25, 25, 32)        8224      \n",
      "_________________________________________________________________\n",
      "conv2d_40 (Conv2D)           (None, 25, 25, 5)         165       \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_3 ( (None, 5)                 0         \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 5)                 0         \n",
      "=================================================================\n",
      "Total params: 145,477\n",
      "Trainable params: 145,285\n",
      "Non-trainable params: 192\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 영택이 모델 + 배치정규화 버전 + 드롭아웃 삭제\n",
    "from keras.layers import BatchNormalization, Dropout\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D, Dropout, Activation, Average\n",
    "def young_cnn(model_input):\n",
    "    \n",
    "    #mlpconv block 1\n",
    "    x = Conv2D(32, (3, 3), activation='relu',padding='same')(model_input)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "   \n",
    "    \n",
    "        #mlpconv block2\n",
    "    x = Conv2D(64, (3, 3), activation='relu',padding='same')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(64, (1, 1), activation='relu')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    #mlpconv block3\n",
    "    x = Conv2D(128, (3, 3), activation='relu',padding='same')(x)\n",
    "    x = Conv2D(256, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(32, (1, 1), activation='relu')(x)\n",
    "    x = Conv2D(5, (1, 1))(x)\n",
    "    \n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Activation(activation='softmax')(x)\n",
    "    \n",
    "    model = Model(model_input, x, name='young_cnn')\n",
    "    \n",
    "    return model\n",
    "    \n",
    "young_cnn_model =  young_cnn(model_input)\n",
    "young_cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2411 samples, validate on 603 samples\n",
      "Epoch 1/20\n",
      "2411/2411 [==============================] - 45s 19ms/step - loss: 1.3985 - acc: 0.3874 - val_loss: 1.8120 - val_acc: 0.1990\n",
      "Epoch 2/20\n",
      "2411/2411 [==============================] - 44s 18ms/step - loss: 1.1240 - acc: 0.5313 - val_loss: 2.1891 - val_acc: 0.1940\n",
      "Epoch 3/20\n",
      "2411/2411 [==============================] - 43s 18ms/step - loss: 0.9738 - acc: 0.5761 - val_loss: 2.7490 - val_acc: 0.1940\n",
      "Epoch 4/20\n",
      "2411/2411 [==============================] - 43s 18ms/step - loss: 0.9015 - acc: 0.6188 - val_loss: 3.4105 - val_acc: 0.1940\n",
      "Epoch 5/20\n",
      "2411/2411 [==============================] - 43s 18ms/step - loss: 0.7904 - acc: 0.6661 - val_loss: 2.5341 - val_acc: 0.1940\n",
      "Epoch 6/20\n",
      "2411/2411 [==============================] - 44s 18ms/step - loss: 0.7107 - acc: 0.7047 - val_loss: 2.2719 - val_acc: 0.1990\n",
      "Epoch 7/20\n",
      "2411/2411 [==============================] - 43s 18ms/step - loss: 0.7147 - acc: 0.7238 - val_loss: 1.2542 - val_acc: 0.4478\n",
      "Epoch 8/20\n",
      "2411/2411 [==============================] - 43s 18ms/step - loss: 0.6277 - acc: 0.7590 - val_loss: 1.4152 - val_acc: 0.4312\n",
      "Epoch 9/20\n",
      "2411/2411 [==============================] - 43s 18ms/step - loss: 0.5785 - acc: 0.7802 - val_loss: 0.9304 - val_acc: 0.6103\n",
      "Epoch 10/20\n",
      "2411/2411 [==============================] - 41s 17ms/step - loss: 0.5224 - acc: 0.8088 - val_loss: 1.0000 - val_acc: 0.5871\n",
      "Epoch 11/20\n",
      "2411/2411 [==============================] - 42s 18ms/step - loss: 0.4863 - acc: 0.8237 - val_loss: 1.4962 - val_acc: 0.4925\n",
      "Epoch 12/20\n",
      "2411/2411 [==============================] - 41s 17ms/step - loss: 0.4434 - acc: 0.8382 - val_loss: 1.6200 - val_acc: 0.5738\n",
      "Epoch 13/20\n",
      "2411/2411 [==============================] - 39s 16ms/step - loss: 0.4043 - acc: 0.8548 - val_loss: 0.4665 - val_acc: 0.8308\n",
      "Epoch 14/20\n",
      "2411/2411 [==============================] - 39s 16ms/step - loss: 0.3413 - acc: 0.8789 - val_loss: 0.6469 - val_acc: 0.7512\n",
      "Epoch 15/20\n",
      "2411/2411 [==============================] - 39s 16ms/step - loss: 0.3428 - acc: 0.8739 - val_loss: 0.5240 - val_acc: 0.8010\n",
      "Epoch 16/20\n",
      "2411/2411 [==============================] - 36s 15ms/step - loss: 0.3225 - acc: 0.8843 - val_loss: 0.6846 - val_acc: 0.7662\n",
      "Epoch 17/20\n",
      "2411/2411 [==============================] - 33s 14ms/step - loss: 0.2637 - acc: 0.9025 - val_loss: 1.4550 - val_acc: 0.6401\n",
      "Epoch 18/20\n",
      "2411/2411 [==============================] - 37s 15ms/step - loss: 0.2687 - acc: 0.9058 - val_loss: 0.5285 - val_acc: 0.7894\n",
      "Epoch 19/20\n",
      "2411/2411 [==============================] - 39s 16ms/step - loss: 0.2095 - acc: 0.9316 - val_loss: 0.4494 - val_acc: 0.8292\n",
      "Epoch 20/20\n",
      "2411/2411 [==============================] - 38s 16ms/step - loss: 0.2086 - acc: 0.9241 - val_loss: 0.6965 - val_acc: 0.7711\n"
     ]
    }
   ],
   "source": [
    "from keras.losses import categorical_crossentropy\n",
    "from keras.optimizers import Adam\n",
    "def compile_and_train(model, num_epochs):\n",
    "    model.compile(loss = categorical_crossentropy, optimizer=Adam(), metrics=['acc'])\n",
    "    history= model.fit(x=X_train, y=y_train, batch_size=32, epochs=num_epochs, verbose=1,\n",
    "                       validation_split =0.2)\n",
    "    \n",
    "_ = compile_and_train(young_cnn_model, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1005/1005 [==============================] - 7s 7ms/step\n",
      "정확도 : 0.7612\n"
     ]
    }
   ],
   "source": [
    "print(\"정확도 : %.4f\" % (young_cnn_model.evaluate(X_test, y_test)[1]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
